#!/usr/bin/env python3
"""
ê°œì„ ëœ ëª¨ë“œíŒ© íŒŒì„œ - Enigmatica 10, Prominence 2 ë“± ëŒ€í˜• ëª¨ë“œíŒ© ì§€ì›
ê¸°ì¡´ modpack_parser.pyì˜ í™•ì¥ ë²„ì „
"""

import os
import json
import re
from typing import List, Dict, Any, Tuple, Set
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

class EnhancedModpackParser:
    """ëŒ€í˜• ëª¨ë“œíŒ© ì „ìš© í–¥ìƒëœ íŒŒì„œ"""
    
    def __init__(self):
        self.supported_recipe_types = {
            'minecraft:crafting_shaped',
            'minecraft:crafting_shapeless', 
            'minecraft:smelting',
            'minecraft:blasting',
            'minecraft:smoking',
            'minecraft:campfire_cooking',
            'thermal:pulverizer',
            'thermal:smelter',
            'thermal:centrifuge',
            'mekanism:enriching',
            'mekanism:crushing',
            'mekanism:smelting',
            'create:mixing',
            'create:pressing',
            'create:cutting',
            'appliedenergistics2:grinder',
            'appliedenergistics2:inscriber'
        }
        
        self.mod_categories = {
            'tech': ['thermal', 'mekanism', 'industrialcraft', 'applied', 'refined'],
            'magic': ['thaumcraft', 'botania', 'blood', 'astral', 'embers'],
            'exploration': ['twilight', 'aether', 'dimensional', 'mining'],
            'automation': ['create', 'integrated', 'xnet', 'logistics'],
            'storage': ['applied', 'refined', 'storage', 'colossal'],
            'tools': ['tinkers', 'thermal', 'mekanism', 'ender']
        }
    
    def scan_enhanced_modpack(self, modpack_path: str) -> Dict[str, Any]:
        """í–¥ìƒëœ ëª¨ë“œíŒ© ìŠ¤ìº”"""
        print(f"ğŸ” í–¥ìƒëœ ëª¨ë“œíŒ© ìŠ¤ìº” ì‹œì‘: {modpack_path}")
        
        if not os.path.exists(modpack_path):
            return {'docs': [], 'stats': {}, 'error': 'Path not found'}
        
        docs = []
        stats = {
            'recipes': 0,
            'mods': 0, 
            'kubejs': 0,
            'configs': 0,
            'quests': 0,
            'lang_files': 0,
            'mod_categories': {},
            'recipe_types': {}
        }
        
        # 1. ëª¨ë“œ ë¶„ì„ (í–¥ìƒëœ ë²„ì „)
        mod_docs, mod_stats = self._analyze_mods_enhanced(modpack_path)
        docs.extend(mod_docs)
        stats.update(mod_stats)
        
        # 2. ë ˆì‹œí”¼ ë¶„ì„ (í™•ì¥ëœ ì§€ì›)
        recipe_docs, recipe_stats = self._analyze_recipes_enhanced(modpack_path)
        docs.extend(recipe_docs)
        stats['recipes'] = recipe_stats['count']
        stats['recipe_types'] = recipe_stats['types']
        
        # 3. KubeJS ìŠ¤í¬ë¦½íŠ¸ ë¶„ì„
        kubejs_docs, kubejs_count = self._analyze_kubejs_enhanced(modpack_path)
        docs.extend(kubejs_docs)
        stats['kubejs'] = kubejs_count
        
        # 4. ì„¤ì • íŒŒì¼ ë¶„ì„
        config_docs, config_count = self._analyze_configs(modpack_path)
        docs.extend(config_docs)
        stats['configs'] = config_count
        
        # 5. í€˜ìŠ¤íŠ¸ ë¶„ì„ (FTB Quests, HQM ë“±)
        quest_docs, quest_count = self._analyze_quests(modpack_path)
        docs.extend(quest_docs)
        stats['quests'] = quest_count
        
        # 6. ì–¸ì–´ íŒŒì¼ ë¶„ì„ (ë‹¤êµ­ì–´ ì§€ì›)
        lang_docs, lang_count = self._analyze_lang_files(modpack_path)
        docs.extend(lang_docs)
        stats['lang_files'] = lang_count
        
        print(f"âœ… ìŠ¤ìº” ì™„ë£Œ: {len(docs)}ê°œ ë¬¸ì„œ, {stats}")
        
        return {
            'docs': docs,
            'stats': stats,
            'modpack_analysis': self._analyze_modpack_type(stats, docs)
        }
    
    def _analyze_mods_enhanced(self, modpack_path: str) -> Tuple[List[Dict], Dict]:
        """í–¥ìƒëœ ëª¨ë“œ ë¶„ì„"""
        mods_dir = os.path.join(modpack_path, 'mods')
        if not os.path.isdir(mods_dir):
            return [], {'mods': 0, 'mod_categories': {}}
        
        docs = []
        mod_categories = {cat: 0 for cat in self.mod_categories}
        
        try:
            jar_files = [f for f in os.listdir(mods_dir) if f.lower().endswith('.jar')]
            
            for jar_file in jar_files:
                # ëª¨ë“œëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ
                mod_name = self._extract_mod_name(jar_file)
                mod_category = self._categorize_mod(mod_name)
                
                if mod_category:
                    mod_categories[mod_category] += 1
                
                # í–¥ìƒëœ í…ìŠ¤íŠ¸ ì •ë³´
                text = f"Mod: {mod_name} (category: {mod_category or 'general'})"
                if self._is_major_mod(mod_name):
                    text += " [MAJOR MOD]"
                
                docs.append({
                    'type': 'mod',
                    'mod_name': mod_name,
                    'category': mod_category,
                    'is_major': self._is_major_mod(mod_name),
                    'source': os.path.join(mods_dir, jar_file),
                    'text': text
                })
            
            return docs, {'mods': len(jar_files), 'mod_categories': mod_categories}
            
        except Exception as e:
            logger.error(f"ëª¨ë“œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return [], {'mods': 0, 'mod_categories': {}}
    
    def _analyze_recipes_enhanced(self, modpack_path: str) -> Tuple[List[Dict], Dict]:
        """í™•ì¥ëœ ë ˆì‹œí”¼ ë¶„ì„"""
        data_dir = os.path.join(modpack_path, 'data')
        if not os.path.isdir(data_dir):
            return [], {'count': 0, 'types': {}}
        
        docs = []
        recipe_types = {}
        
        for root, _, files in os.walk(data_dir):
            for file_name in files:
                if not file_name.endswith('.json'):
                    continue
                
                file_path = os.path.join(root, file_name)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    recipe_type = data.get('type', 'unknown')
                    recipe_types[recipe_type] = recipe_types.get(recipe_type, 0) + 1
                    
                    # í–¥ìƒëœ ë ˆì‹œí”¼ íŒŒì‹±
                    recipe_doc = self._parse_recipe_enhanced(data, file_path, recipe_type)
                    if recipe_doc:
                        docs.append(recipe_doc)
                        
                except Exception as e:
                    logger.debug(f"ë ˆì‹œí”¼ íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨ {file_path}: {e}")
                    continue
        
        return docs, {'count': len(docs), 'types': recipe_types}
    
    def _parse_recipe_enhanced(self, recipe_data: Dict, file_path: str, recipe_type: str) -> Dict:
        """í–¥ìƒëœ ë ˆì‹œí”¼ íŒŒì‹±"""
        result = recipe_data.get('result')
        
        # ê²°ê³¼ ì•„ì´í…œ ì •ë³´ ì¶”ì¶œ
        result_item = "unknown"
        result_count = 1
        
        if isinstance(result, dict):
            result_item = result.get('item') or result.get('id') or "unknown"
            result_count = result.get('count', 1)
        elif isinstance(result, str):
            result_item = result
        elif isinstance(result, list) and result:
            # ë‹¤ì¤‘ ê²°ê³¼ ì²˜ë¦¬
            first_result = result[0]
            if isinstance(first_result, dict):
                result_item = first_result.get('item') or first_result.get('id') or "unknown"
                result_count = first_result.get('count', 1)
        
        # ì…ë ¥ ì¬ë£Œ ì •ë³´ ì¶”ì¶œ
        ingredients = self._extract_ingredients(recipe_data)
        
        # ëª¨ë“œ ì´ë¦„ ì¶”ì¶œ
        mod_id = result_item.split(':')[0] if ':' in result_item else 'minecraft'
        
        # í–¥ìƒëœ í…ìŠ¤íŠ¸ ìƒì„±
        clean_item = result_item.split(':')[-1].replace('_', ' ')
        text_parts = [
            f"Recipe: {clean_item} x{result_count}",
            f"Type: {recipe_type.split(':')[-1]}",
            f"Mod: {mod_id}"
        ]
        
        if ingredients:
            text_parts.append(f"Ingredients: {', '.join(ingredients[:3])}")
        
        return {
            'type': 'recipe',
            'subtype': recipe_type,
            'result_item': result_item,
            'result_count': result_count,
            'mod_id': mod_id,
            'ingredients': ingredients,
            'source': file_path,
            'text': ' | '.join(text_parts)
        }
    
    def _extract_ingredients(self, recipe_data: Dict) -> List[str]:
        """ë ˆì‹œí”¼ ì¬ë£Œ ì •ë³´ ì¶”ì¶œ"""
        ingredients = []
        
        # ingredients í•„ë“œ
        if 'ingredients' in recipe_data:
            for ing in recipe_data['ingredients']:
                if isinstance(ing, dict):
                    item = ing.get('item') or ing.get('tag') or ""
                    if item:
                        ingredients.append(item.split(':')[-1].replace('_', ' '))
        
        # patternê³¼ key ì¡°í•© (shaped recipes)
        if 'pattern' in recipe_data and 'key' in recipe_data:
            key_map = recipe_data['key']
            for symbol, spec in key_map.items():
                if isinstance(spec, dict):
                    item = spec.get('item') or spec.get('tag') or ""
                    if item:
                        ingredients.append(item.split(':')[-1].replace('_', ' '))
        
        # input í•„ë“œ (ê¸°ê³„ ë ˆì‹œí”¼)
        if 'input' in recipe_data:
            input_data = recipe_data['input']
            if isinstance(input_data, dict):
                item = input_data.get('item') or input_data.get('tag') or ""
                if item:
                    ingredients.append(item.split(':')[-1].replace('_', ' '))
            elif isinstance(input_data, list):
                for inp in input_data:
                    if isinstance(inp, dict):
                        item = inp.get('item') or inp.get('tag') or ""
                        if item:
                            ingredients.append(item.split(':')[-1].replace('_', ' '))
        
        return ingredients[:5]  # ìµœëŒ€ 5ê°œ ì¬ë£Œë§Œ
    
    def _analyze_kubejs_enhanced(self, modpack_path: str) -> Tuple[List[Dict], int]:
        """í–¥ìƒëœ KubeJS ë¶„ì„"""
        kubejs_dir = os.path.join(modpack_path, 'kubejs')
        if not os.path.isdir(kubejs_dir):
            return [], 0
        
        docs = []
        
        for root, _, files in os.walk(kubejs_dir):
            for file_name in files:
                if not file_name.endswith(('.js', '.json')):
                    continue
                
                file_path = os.path.join(root, file_name)
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read(3000)  # ë” ë§ì€ ë‚´ìš© ì½ê¸°
                    
                    # ìŠ¤í¬ë¦½íŠ¸ íƒ€ì… ë¶„ì„
                    script_type = self._analyze_kubejs_type(content, file_path)
                    
                    # ë‚´ìš© ìš”ì•½
                    summary = self._summarize_kubejs_content(content)
                    
                    relative_path = os.path.relpath(file_path, kubejs_dir)
                    text = f"KubeJS {script_type}: {relative_path} | {summary}"
                    
                    docs.append({
                        'type': 'kubejs',
                        'script_type': script_type,
                        'summary': summary,
                        'source': file_path,
                        'text': text
                    })
                    
                except Exception as e:
                    logger.debug(f"KubeJS íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ {file_path}: {e}")
        
        return docs, len(docs)
    
    def _analyze_configs(self, modpack_path: str) -> Tuple[List[Dict], int]:
        """ì„¤ì • íŒŒì¼ ë¶„ì„"""
        config_dir = os.path.join(modpack_path, 'config')
        if not os.path.isdir(config_dir):
            return [], 0
        
        docs = []
        important_configs = {
            'thermal.toml', 'mekanism.toml', 'create.toml', 
            'appliedenergistics2.toml', 'botania.toml'
        }
        
        for root, _, files in os.walk(config_dir):
            for file_name in files:
                if file_name not in important_configs:
                    continue
                
                file_path = os.path.join(root, file_name)
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read(1000)
                    
                    mod_name = file_name.replace('.toml', '')
                    text = f"Config: {mod_name} | {content[:200].replace('\n', ' ')}"
                    
                    docs.append({
                        'type': 'config',
                        'mod_name': mod_name,
                        'source': file_path,
                        'text': text
                    })
                    
                except Exception as e:
                    logger.debug(f"ì„¤ì • íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ {file_path}: {e}")
        
        return docs, len(docs)
    
    def _analyze_quests(self, modpack_path: str) -> Tuple[List[Dict], int]:
        """í€˜ìŠ¤íŠ¸ ì‹œìŠ¤í…œ ë¶„ì„"""
        docs = []
        quest_dirs = ['ftbquests', 'config/ftbquests', 'questbook', 'config/hqm']
        
        for quest_dir_name in quest_dirs:
            quest_dir = os.path.join(modpack_path, quest_dir_name)
            if not os.path.isdir(quest_dir):
                continue
            
            for root, _, files in os.walk(quest_dir):
                for file_name in files:
                    if not file_name.endswith('.snbt'):
                        continue
                    
                    file_path = os.path.join(root, file_name)
                    try:
                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read(2000)
                        
                        # í€˜ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ
                        quest_info = self._extract_quest_info(content)
                        
                        text = f"Quest: {quest_info.get('title', file_name)} | {quest_info.get('description', '')[:100]}"
                        
                        docs.append({
                            'type': 'quest',
                            'quest_info': quest_info,
                            'source': file_path,
                            'text': text
                        })
                        
                    except Exception as e:
                        logger.debug(f"í€˜ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ {file_path}: {e}")
        
        return docs, len(docs)
    
    def _analyze_lang_files(self, modpack_path: str) -> Tuple[List[Dict], int]:
        """ì–¸ì–´ íŒŒì¼ ë¶„ì„ (êµ­ì œí™” ì§€ì›)"""
        docs = []
        
        # ì–¸ì–´ íŒŒì¼ ìœ„ì¹˜ë“¤
        lang_locations = [
            'assets/*/lang/*.json',
            'resourcepacks/*/assets/*/lang/*.json'
        ]
        
        for location_pattern in lang_locations:
            import glob
            pattern = os.path.join(modpack_path, location_pattern)
            
            for file_path in glob.glob(pattern, recursive=True):
                if 'ko_kr.json' not in file_path and 'en_us.json' not in file_path:
                    continue
                
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        lang_data = json.load(f)
                    
                    lang_code = 'ko_kr' if 'ko_kr' in file_path else 'en_us'
                    mod_id = self._extract_mod_from_path(file_path)
                    
                    # ì¤‘ìš”í•œ ë²ˆì—­ í•­ëª©ë“¤ë§Œ ì¶”ì¶œ
                    important_keys = [k for k in lang_data.keys() 
                                    if any(term in k.lower() for term in ['item.', 'block.', 'gui.'])]
                    
                    if important_keys:
                        sample_translations = {k: lang_data[k] for k in important_keys[:10]}
                        text = f"Lang ({lang_code}): {mod_id} | {len(lang_data)} translations"
                        
                        docs.append({
                            'type': 'lang',
                            'lang_code': lang_code,
                            'mod_id': mod_id,
                            'translation_count': len(lang_data),
                            'sample_translations': sample_translations,
                            'source': file_path,
                            'text': text
                        })
                
                except Exception as e:
                    logger.debug(f"ì–¸ì–´ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ {file_path}: {e}")
        
        return docs, len(docs)
    
    def _extract_mod_name(self, jar_filename: str) -> str:
        """JAR íŒŒì¼ëª…ì—ì„œ ëª¨ë“œëª… ì¶”ì¶œ"""
        # ë²„ì „ ë²ˆí˜¸ ì œê±°
        name = re.sub(r'-\d+\.\d+.*\.jar$', '', jar_filename, flags=re.IGNORECASE)
        name = name.replace('.jar', '')
        return name.lower()
    
    def _categorize_mod(self, mod_name: str) -> str:
        """ëª¨ë“œë¥¼ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜"""
        for category, keywords in self.mod_categories.items():
            if any(keyword in mod_name for keyword in keywords):
                return category
        return None
    
    def _is_major_mod(self, mod_name: str) -> bool:
        """ì£¼ìš” ëª¨ë“œì¸ì§€ í™•ì¸"""
        major_mods = {
            'thermal', 'mekanism', 'create', 'appliedenergistics', 'refined',
            'tinkers', 'botania', 'thaumcraft', 'industrialcraft', 'buildcraft'
        }
        return any(major in mod_name for major in major_mods)
    
    def _analyze_kubejs_type(self, content: str, file_path: str) -> str:
        """KubeJS ìŠ¤í¬ë¦½íŠ¸ íƒ€ì… ë¶„ì„"""
        if 'recipe' in content.lower():
            return 'recipe_modification'
        elif 'startup' in file_path:
            return 'startup_script'
        elif 'server' in file_path:
            return 'server_script'
        elif 'client' in file_path:
            return 'client_script'
        else:
            return 'general_script'
    
    def _summarize_kubejs_content(self, content: str) -> str:
        """KubeJS ë‚´ìš© ìš”ì•½"""
        keywords = []
        
        if 'recipe' in content.lower():
            keywords.append('recipe changes')
        if 'remove' in content.lower():
            keywords.append('recipe removal')
        if 'shaped' in content.lower():
            keywords.append('shaped crafting')
        if 'smelting' in content.lower():
            keywords.append('smelting')
        
        return ', '.join(keywords) if keywords else 'script modifications'
    
    def _extract_quest_info(self, content: str) -> Dict[str, str]:
        """í€˜ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ"""
        info = {}
        
        # ì œëª© ì¶”ì¶œ
        title_match = re.search(r'title:\s*"([^"]+)"', content)
        if title_match:
            info['title'] = title_match.group(1)
        
        # ì„¤ëª… ì¶”ì¶œ
        desc_match = re.search(r'description:\s*\[([^\]]+)\]', content)
        if desc_match:
            info['description'] = desc_match.group(1).replace('"', '').replace(',', ' ')
        
        return info
    
    def _extract_mod_from_path(self, file_path: str) -> str:
        """íŒŒì¼ ê²½ë¡œì—ì„œ ëª¨ë“œ ID ì¶”ì¶œ"""
        parts = file_path.split(os.sep)
        for i, part in enumerate(parts):
            if part == 'assets' and i + 1 < len(parts):
                return parts[i + 1]
        return 'unknown'
    
    def _analyze_modpack_type(self, stats: Dict, docs: List[Dict]) -> Dict[str, Any]:
        """ëª¨ë“œíŒ© íƒ€ì… ë¶„ì„"""
        analysis = {
            'modpack_type': 'unknown',
            'complexity': 'medium',
            'primary_focus': 'mixed',
            'has_quests': stats.get('quests', 0) > 0,
            'has_custom_recipes': stats.get('kubejs', 0) > 0,
            'tech_heavy': False,
            'magic_heavy': False
        }
        
        # ëª¨ë“œ ì¹´í…Œê³ ë¦¬ ë¶„ì„
        categories = stats.get('mod_categories', {})
        tech_mods = categories.get('tech', 0)
        magic_mods = categories.get('magic', 0)
        
        if tech_mods > magic_mods * 2:
            analysis['primary_focus'] = 'tech'
            analysis['tech_heavy'] = True
        elif magic_mods > tech_mods * 2:
            analysis['primary_focus'] = 'magic'
            analysis['magic_heavy'] = True
        
        # ë³µì¡ë„ ê²°ì •
        total_docs = len(docs)
        if total_docs > 1000:
            analysis['complexity'] = 'high'
        elif total_docs < 200:
            analysis['complexity'] = 'low'
        
        # ëª¨ë“œíŒ© íƒ€ì… ì¶”ì •
        if analysis['has_quests'] and total_docs > 500:
            analysis['modpack_type'] = 'expert'
        elif tech_mods > 10:
            analysis['modpack_type'] = 'tech'
        elif magic_mods > 5:
            analysis['modpack_type'] = 'magic'
        
        return analysis


def main():
    """í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    parser = EnhancedModpackParser()
    
    # í…ŒìŠ¤íŠ¸ìš© ê²½ë¡œ (ì‹¤ì œ ì‚¬ìš©ì‹œ ìˆ˜ì • í•„ìš”)
    test_path = input("í…ŒìŠ¤íŠ¸í•  ëª¨ë“œíŒ© ê²½ë¡œ: ")
    
    if os.path.exists(test_path):
        result = parser.scan_enhanced_modpack(test_path)
        
        print(f"\nğŸ“Š ìŠ¤ìº” ê²°ê³¼:")
        print(f"ì´ ë¬¸ì„œ: {len(result['docs'])}ê°œ")
        print(f"í†µê³„: {result['stats']}")
        print(f"ë¶„ì„: {result['modpack_analysis']}")
    else:
        print(f"âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {test_path}")


if __name__ == "__main__":
    main()