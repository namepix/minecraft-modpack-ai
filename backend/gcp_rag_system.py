# GCP ê¸°ë°˜ RAG ì‹œìŠ¤í…œ
# ëª¨ë“œíŒ© ë°ì´í„°ë¥¼ GCPì— ì €ì¥í•˜ê³  ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰

import os
import json
import hashlib
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
import logging

# GCP ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from google.cloud import firestore
    from google.cloud import aiplatform
    from vertexai.language_models import TextEmbeddingModel
    GCP_AVAILABLE = True
except ImportError:
    GCP_AVAILABLE = False
    print("âš ï¸ GCP ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. pip install google-cloud-firestore google-cloud-aiplatform vertexai í•„ìš”")

# ê¸°ì¡´ ëª¨ë“ˆ
from modpack_parser import scan_modpack

logger = logging.getLogger(__name__)

class GCPRAGSystem:
    """GCP ê¸°ë°˜ RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self, project_id: str = None, location: str = "us-central1"):
        self.project_id = project_id or os.getenv('GCP_PROJECT_ID')
        self.location = location
        self.enabled = False
        
        if not GCP_AVAILABLE:
            logger.warning("GCP ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆê°€ëŠ¥ - RAG ì‹œìŠ¤í…œ ë¹„í™œì„±í™”")
            return
            
        if not self.project_id:
            logger.warning("GCP_PROJECT_ID í™˜ê²½ë³€ìˆ˜ ì—†ìŒ - RAG ì‹œìŠ¤í…œ ë¹„í™œì„±í™”")
            return
            
        try:
            # Firestore í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            self.db = firestore.Client(project=self.project_id)
            
            # Vertex AI ì´ˆê¸°í™”
            aiplatform.init(project=self.project_id, location=self.location)
            self.embedding_model = TextEmbeddingModel.from_pretrained("textembedding-gecko@003")
            
            self.enabled = True
            logger.info(f"âœ… GCP RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ - Project: {self.project_id}")
            
        except Exception as e:
            logger.error(f"âŒ GCP RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.enabled = False

    def is_enabled(self) -> bool:
        """RAG ì‹œìŠ¤í…œì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        return self.enabled
    
    def _generate_doc_id(self, modpack_name: str, modpack_version: str, doc_source: str) -> str:
        """ë¬¸ì„œ ê³ ìœ  ID ìƒì„±"""
        content = f"{modpack_name}:{modpack_version}:{doc_source}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def _chunk_text(self, text: str, max_chars: int = 1000) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì ì ˆí•œ í¬ê¸°ë¡œ ë¶„í• """
        if len(text) <= max_chars:
            return [text]
        
        chunks = []
        words = text.split(' ')
        current_chunk = []
        current_length = 0
        
        for word in words:
            word_length = len(word) + 1  # ê³µë°± í¬í•¨
            if current_length + word_length > max_chars and current_chunk:
                chunks.append(' '.join(current_chunk))
                current_chunk = [word]
                current_length = len(word)
            else:
                current_chunk.append(word)
                current_length += word_length
        
        if current_chunk:
            chunks.append(' '.join(current_chunk))
        
        return chunks

    def build_modpack_index(self, modpack_name: str, modpack_version: str, modpack_path: str) -> Dict[str, Any]:
        """ëª¨ë“œíŒ© ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  GCPì— ì¸ë±ìŠ¤ êµ¬ì¶•"""
        if not self.enabled:
            return {"success": False, "error": "GCP RAG ì‹œìŠ¤í…œ ë¹„í™œì„±í™”"}
        
        try:
            logger.info(f"ğŸ“¦ ëª¨ë“œíŒ© ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œì‘: {modpack_name} v{modpack_version}")
            
            # 1. ëª¨ë“œíŒ© ë°ì´í„° ìŠ¤ìº”
            scan_result = scan_modpack(modpack_path)
            docs = scan_result.get('docs', [])
            stats = scan_result.get('stats', {})
            
            if not docs:
                return {"success": False, "error": "ë¶„ì„í•  ë¬¸ì„œê°€ ì—†ìŒ"}
            
            # 2. ì»¬ë ‰ì…˜ ì´ë¦„ ìƒì„±
            collection_name = f"modpack_{modpack_name}_{modpack_version}".replace('.', '_').replace('-', '_')
            collection_ref = self.db.collection(collection_name)
            
            # 3. ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì¬êµ¬ì¶• ì‹œ)
            try:
                existing_docs = collection_ref.limit(100).stream()
                batch = self.db.batch()
                delete_count = 0
                for doc in existing_docs:
                    batch.delete(doc.reference)
                    delete_count += 1
                if delete_count > 0:
                    batch.commit()
                    logger.info(f"ğŸ—‘ï¸ ê¸°ì¡´ ë¬¸ì„œ {delete_count}ê°œ ì‚­ì œ")
            except Exception as e:
                logger.warning(f"ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
            
            # 4. ë¬¸ì„œë³„ ë²¡í„°í™” ë° ì €ì¥
            batch = self.db.batch()
            processed_count = 0
            embedding_texts = []
            doc_metadata = []
            
            for doc in docs:
                doc_text = doc.get('text', '')
                if not doc_text:
                    continue
                
                # í…ìŠ¤íŠ¸ ì²­í‚¹
                chunks = self._chunk_text(doc_text, max_chars=800)
                
                for i, chunk in enumerate(chunks):
                    doc_id = self._generate_doc_id(modpack_name, modpack_version, 
                                                 f"{doc.get('source', 'unknown')}_{i}")
                    
                    embedding_texts.append(chunk)
                    doc_metadata.append({
                        'doc_id': doc_id,
                        'modpack_name': modpack_name,
                        'modpack_version': modpack_version,
                        'doc_type': doc.get('type', 'unknown'),
                        'doc_source': doc.get('source', 'unknown'),
                        'text': chunk,
                        'chunk_index': i,
                        'created_at': datetime.utcnow(),
                        'original_doc': doc
                    })
            
            # 5. ì„ë² ë”© ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬)
            logger.info(f"ğŸ”„ ì„ë² ë”© ìƒì„± ì¤‘... ({len(embedding_texts)}ê°œ í…ìŠ¤íŠ¸)")
            
            # Vertex AIì˜ ë°°ì¹˜ í¬ê¸° ì œí•œ ê³ ë ¤
            batch_size = 100
            all_embeddings = []
            
            for i in range(0, len(embedding_texts), batch_size):
                batch_texts = embedding_texts[i:i + batch_size]
                try:
                    embeddings_response = self.embedding_model.get_embeddings(batch_texts)
                    batch_embeddings = [emb.values for emb in embeddings_response]
                    all_embeddings.extend(batch_embeddings)
                    logger.info(f"âœ… ë°°ì¹˜ {i//batch_size + 1} ì™„ë£Œ")
                except Exception as e:
                    logger.error(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ (ë°°ì¹˜ {i//batch_size + 1}): {e}")
                    continue
            
            if len(all_embeddings) != len(doc_metadata):
                return {"success": False, "error": f"ì„ë² ë”© ìˆ˜({len(all_embeddings)})ì™€ ë¬¸ì„œ ìˆ˜({len(doc_metadata)}) ë¶ˆì¼ì¹˜"}
            
            # 6. Firestoreì— ì €ì¥
            logger.info(f"ğŸ’¾ Firestoreì— ì €ì¥ ì¤‘...")
            batch = self.db.batch()
            
            for metadata, embedding in zip(doc_metadata, all_embeddings):
                doc_ref = collection_ref.document(metadata['doc_id'])
                
                # Firestore ë°ì´í„° ì¤€ë¹„
                firestore_data = {
                    'modpack_name': metadata['modpack_name'],
                    'modpack_version': metadata['modpack_version'],
                    'doc_type': metadata['doc_type'],
                    'doc_source': metadata['doc_source'],
                    'text': metadata['text'],
                    'chunk_index': metadata['chunk_index'],
                    'embedding': embedding,
                    'created_at': metadata['created_at'],
                    'text_length': len(metadata['text'])
                }
                
                batch.set(doc_ref, firestore_data)
                processed_count += 1
                
                # Firestore ë°°ì¹˜ ì œí•œ (500ê°œ)
                if processed_count % 400 == 0:
                    batch.commit()
                    batch = self.db.batch()
                    logger.info(f"ğŸ“ {processed_count}ê°œ ë¬¸ì„œ ì €ì¥ ì™„ë£Œ")
            
            # ë‚¨ì€ ë¬¸ì„œë“¤ ì €ì¥
            if processed_count % 400 != 0:
                batch.commit()
            
            # 7. ë©”íƒ€ë°ì´í„° ì»¬ë ‰ì…˜ì— ëª¨ë“œíŒ© ì •ë³´ ì €ì¥
            metadata_ref = self.db.collection('modpack_metadata').document(f"{modpack_name}_{modpack_version}")
            metadata_ref.set({
                'modpack_name': modpack_name,
                'modpack_version': modpack_version,
                'modpack_path': modpack_path,
                'collection_name': collection_name,
                'document_count': processed_count,
                'stats': stats,
                'created_at': datetime.utcnow(),
                'last_updated': datetime.utcnow()
            })
            
            logger.info(f"ğŸ‰ ëª¨ë“œíŒ© ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {processed_count}ê°œ ë¬¸ì„œ")
            
            return {
                "success": True,
                "modpack_name": modpack_name,
                "modpack_version": modpack_version,
                "collection_name": collection_name,
                "document_count": processed_count,
                "stats": stats
            }
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë“œíŒ© ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}

    def search_documents(self, query: str, modpack_name: str, modpack_version: str, 
                        top_k: int = 5, min_score: float = 0.7) -> List[Dict[str, Any]]:
        """ëª¨ë“œíŒ©ì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰"""
        if not self.enabled:
            return []
        
        try:
            # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self.embedding_model.get_embeddings([query])[0].values
            
            # 2. ì»¬ë ‰ì…˜ ì°¸ì¡°
            collection_name = f"modpack_{modpack_name}_{modpack_version}".replace('.', '_').replace('-', '_')
            collection_ref = self.db.collection(collection_name)
            
            # 3. ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ (FirestoreëŠ” ë²¡í„° ê²€ìƒ‰ ë¯¸ì§€ì›ì´ë¯€ë¡œ ë¸Œë£¨íŠ¸í¬ìŠ¤)
            docs = list(collection_ref.stream())
            
            if not docs:
                logger.warning(f"ëª¨ë“œíŒ© ë°ì´í„° ì—†ìŒ: {modpack_name} v{modpack_version}")
                return []
            
            # 4. ìœ ì‚¬ë„ ê³„ì‚°
            results = []
            for doc in docs:
                doc_data = doc.to_dict()
                doc_embedding = doc_data.get('embedding', [])
                
                if not doc_embedding:
                    continue
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                similarity = self._cosine_similarity(query_embedding, doc_embedding)
                
                if similarity >= min_score:
                    results.append({
                        'doc_id': doc.id,
                        'text': doc_data.get('text', ''),
                        'doc_type': doc_data.get('doc_type', 'unknown'),
                        'doc_source': doc_data.get('doc_source', 'unknown'),
                        'similarity': similarity,
                        'text_length': doc_data.get('text_length', 0)
                    })
            
            # 5. ìœ ì‚¬ë„ ê¸°ì¤€ ì •ë ¬ ë° ìƒìœ„ Kê°œ ì„ íƒ
            results.sort(key=lambda x: x['similarity'], reverse=True)
            results = results[:top_k]
            
            logger.info(f"ğŸ” ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ë¬¸ì„œ (ì¿¼ë¦¬: {query[:50]}...)")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _cosine_similarity(self, vec_a: List[float], vec_b: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        if len(vec_a) != len(vec_b):
            return 0.0
        
        dot_product = sum(a * b for a, b in zip(vec_a, vec_b))
        magnitude_a = sum(a * a for a in vec_a) ** 0.5
        magnitude_b = sum(b * b for b in vec_b) ** 0.5
        
        if magnitude_a == 0 or magnitude_b == 0:
            return 0.0
        
        return dot_product / (magnitude_a * magnitude_b)
    
    def get_modpack_list(self) -> List[Dict[str, Any]]:
        """ë“±ë¡ëœ ëª¨ë“œíŒ© ëª©ë¡ ì¡°íšŒ"""
        if not self.enabled:
            return []
        
        try:
            metadata_docs = self.db.collection('modpack_metadata').stream()
            modpacks = []
            
            for doc in metadata_docs:
                data = doc.to_dict()
                modpacks.append({
                    'modpack_name': data.get('modpack_name'),
                    'modpack_version': data.get('modpack_version'),
                    'document_count': data.get('document_count', 0),
                    'created_at': data.get('created_at'),
                    'last_updated': data.get('last_updated'),
                    'stats': data.get('stats', {})
                })
            
            return modpacks
        except Exception as e:
            logger.error(f"ëª¨ë“œíŒ© ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def delete_modpack_index(self, modpack_name: str, modpack_version: str) -> bool:
        """ëª¨ë“œíŒ© ì¸ë±ìŠ¤ ì‚­ì œ"""
        if not self.enabled:
            return False
        
        try:
            # 1. ë¬¸ì„œ ì»¬ë ‰ì…˜ ì‚­ì œ
            collection_name = f"modpack_{modpack_name}_{modpack_version}".replace('.', '_').replace('-', '_')
            collection_ref = self.db.collection(collection_name)
            
            # ë°°ì¹˜ ì‚­ì œ
            docs = list(collection_ref.stream())
            if docs:
                batch = self.db.batch()
                for doc in docs:
                    batch.delete(doc.reference)
                batch.commit()
                logger.info(f"ğŸ—‘ï¸ ì»¬ë ‰ì…˜ {collection_name} ì‚­ì œ ì™„ë£Œ ({len(docs)}ê°œ ë¬¸ì„œ)")
            
            # 2. ë©”íƒ€ë°ì´í„° ì‚­ì œ
            metadata_ref = self.db.collection('modpack_metadata').document(f"{modpack_name}_{modpack_version}")
            metadata_ref.delete()
            
            return True
        except Exception as e:
            logger.error(f"ëª¨ë“œíŒ© ì¸ë±ìŠ¤ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
gcp_rag = GCPRAGSystem()