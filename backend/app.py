from flask import Flask, request, jsonify
from flask_cors import CORS
import os
import json
import requests
from datetime import datetime
from dotenv import load_dotenv
from typing import List, Dict, Any
from pathlib import Path

# ìƒˆë¡œìš´ Gemini SDK
from google import genai
from google.genai import types

# ë³´ì•ˆ ë° ëª¨ë‹ˆí„°ë§ ë¯¸ë“¤ì›¨ì–´
from middleware.security import SecurityMiddleware, require_valid_input, measure_performance
from middleware.monitoring import MonitoringMiddleware, track_model_usage, track_user_activity
from modpack_parser import scan_modpack
# GCP RAG ì‹œìŠ¤í…œ
from gcp_rag_system import gcp_rag

# í‘œì¤€ í™˜ê²½ íŒŒì¼ ê²½ë¡œ ë¡œë“œ
env_file = Path.home() / "minecraft-ai-backend" / ".env"
load_dotenv(env_file)

# ========= ğŸ”§ ê°œì„ ëœ ëª¨ë“œíŒ© íƒ€ê²ŸíŒ… ì‹œìŠ¤í…œ =========

def load_rag_config():
    """RAG ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    import json
    from pathlib import Path
    
    config_file = Path(__file__).parent / "rag_config.json"
    default_config = {
        "rag_mode": "auto",
        "current_modpack": {
            "name": "",
            "version": "1.0.0"
        },
        "manual_modpack_path": ""
    }
    
    if config_file.exists():
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                return {**default_config, **config}
        except Exception as e:
            print(f"âš ï¸ RAG ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    return default_config

def get_target_modpack(request_data):
    """ìš”ì²­ì—ì„œ íƒ€ê²Ÿ ëª¨ë“œíŒ© ê²°ì • (ìˆ˜ë™ ì„¤ì • ìš°ì„ , ìë™ ê°ì§€ í´ë°±)"""
    config = load_rag_config()
    
    # 1. ìˆ˜ë™ ëª¨ë“œ: ì„¤ì •ëœ ëª¨ë“œíŒ© ì‚¬ìš©
    if config.get("rag_mode") == "manual":
        manual_name = config.get("current_modpack", {}).get("name", "")
        manual_version = config.get("current_modpack", {}).get("version", "1.0.0")
        
        if manual_name:
            print(f"ğŸ”§ ìˆ˜ë™ ëª¨ë“œ: {manual_name} v{manual_version}")
            return manual_name, manual_version
        else:
            print("âš ï¸ ìˆ˜ë™ ëª¨ë“œì´ì§€ë§Œ ëª¨ë“œíŒ©ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ, ìë™ ëª¨ë“œë¡œ í´ë°±")
    
    # 2. ìë™ ëª¨ë“œ: ìš”ì²­ì—ì„œ ì¶”ì¶œ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
    request_name = request_data.get('modpack_name', '')
    request_version = request_data.get('modpack_version', '1.0.0')
    
    if request_name and request_name != 'Unknown Modpack':
        print(f"ğŸ¤– ìë™ ê°ì§€: {request_name} v{request_version}")
        return request_name, request_version
    
    # 3. í™˜ê²½ë³€ìˆ˜ í´ë°±
    env_name = os.getenv('CURRENT_MODPACK_NAME', '')
    env_version = os.getenv('CURRENT_MODPACK_VERSION', '1.0.0')
    
    if env_name:
        print(f"ğŸŒ í™˜ê²½ë³€ìˆ˜ í´ë°±: {env_name} v{env_version}")
        return env_name, env_version
    
    # 4. ê¸°ë³¸ê°’
    print("âš ï¸ ëª¨ë“œíŒ© ì •ë³´ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©")
    return "Unknown Modpack", "1.0.0"

app = Flask(__name__)
CORS(app)

# ë¯¸ë“¤ì›¨ì–´ ì´ˆê¸°í™”
security_middleware = SecurityMiddleware(app)
monitoring_middleware = MonitoringMiddleware(app)

# API í‚¤ ì„¤ì •
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')
GEMINI_WEBSEARCH_ENABLED = os.getenv('GEMINI_WEBSEARCH_ENABLED', 'true').lower() == 'true'
GCP_RAG_ENABLED = os.getenv('GCP_RAG_ENABLED', 'true').lower() == 'true'

# ëª¨ë¸ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥)
GEMINI_MODEL = os.getenv('GEMINI_MODEL', 'gemini-2.5-pro')
OPENAI_MODEL_PRIMARY = os.getenv('OPENAI_MODEL_PRIMARY', 'gpt-4o-mini')
OPENAI_MODEL_FALLBACK = os.getenv('OPENAI_MODEL_FALLBACK', 'gpt-3.5-turbo')
CLAUDE_MODEL = os.getenv('CLAUDE_MODEL', 'claude-3-5-sonnet-20241022')
# RAG í”„ë¡¬í”„íŠ¸ ì²¨ë¶€ ì˜ˆì‚°(í™˜ê²½ë³€ìˆ˜ë¡œ ì¡°ì • ê°€ëŠ¥)
RAG_TOP_K = int(os.getenv('RAG_TOP_K', '5'))
RAG_SNIPPET_MAX_CHARS = int(os.getenv('RAG_SNIPPET_MAX_CHARS', '500'))
RAG_TOTAL_MAX_CHARS = int(os.getenv('RAG_TOTAL_MAX_CHARS', '1500'))

# AI ëª¨ë¸ ì´ˆê¸°í™” (ì•ˆì „í•˜ê²Œ)
gemini_client = None
openai_client = None
claude_client = None

# Google AI ì´ˆê¸°í™” - 2025ë…„ ìµœì‹  SDK ë° ì›¹ê²€ìƒ‰ ì§€ì›
if GOOGLE_API_KEY:
    try:
        gemini_client = genai.Client(api_key=GOOGLE_API_KEY)
        print("âœ… Gemini 2.5 Pro í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ì›¹ê²€ìƒ‰ ì§€ì›, google-genai SDK)")
    except Exception as e:
        print(f"âš ï¸ Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        gemini_client = None

# OpenAI ì´ˆê¸°í™” - 2025ë…„ ì—…ë°ì´íŠ¸ëœ ë°©ì‹, ì•ˆì „í•œ ì²˜ë¦¬
if OPENAI_API_KEY and OPENAI_API_KEY != "dummy" and len(OPENAI_API_KEY) > 10:
    try:
        # ìƒˆë¡œìš´ OpenAI í´ë¼ì´ì–¸íŠ¸ ë°©ì‹
        from openai import OpenAI
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
        
        # API í‚¤ ìœ íš¨ì„± ê°„ë‹¨ í…ŒìŠ¤íŠ¸ (ë¹„ìš© ìµœì†Œí™”)
        test_response = openai_client.models.list()
        print("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ë¬´ë£Œ í‹°ì–´)")
    except Exception as e:
        print(f"âš ï¸ OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        openai_client = None
elif OPENAI_API_KEY:
    print("âš ï¸ OpenAI API í‚¤ê°€ ë”ë¯¸ ê°’ì´ê±°ë‚˜ ë„ˆë¬´ ì§§ì•„ì„œ ë¹„í™œì„±í™”ë¨")

# Anthropic ì´ˆê¸°í™” - ì•ˆì „í•œ ì²˜ë¦¬ (ë¬´ë£Œ í‹°ì–´ ì—†ìŒ)
if ANTHROPIC_API_KEY and ANTHROPIC_API_KEY != "dummy" and len(ANTHROPIC_API_KEY) > 10:
    try:
        import anthropic
        claude_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
        
        # API í‚¤ ìœ íš¨ì„± ê°„ë‹¨ í…ŒìŠ¤íŠ¸
        claude_client.models.list()
        print("âœ… Claude í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ìœ ë£Œ API)")
    except Exception as e:
        print(f"âš ï¸ Claude API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        claude_client = None
elif ANTHROPIC_API_KEY:
    print("âš ï¸ Anthropic API í‚¤ê°€ ë”ë¯¸ ê°’ì´ê±°ë‚˜ ë„ˆë¬´ ì§§ì•„ì„œ ë¹„í™œì„±í™”ë¨")

# í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ (ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ëª¨ë¸ ì„ íƒ, Gemini ìš°ì„ )
current_model = "gemini" if gemini_client else "openai" if openai_client else "claude" if claude_client else None

# ========= ê°„ë‹¨ RAG ì»´í¬ë„ŒíŠ¸ (FAISS + SentenceTransformer) =========
rag_enabled = False
rag_index = None
rag_documents: List[Dict[str, Any]] = []
rag_model = None

RAG_DIR = os.path.join(os.path.expanduser('~'), 'minecraft-ai-backend', 'rag')

def init_rag():
    global rag_enabled, rag_index, rag_model
    try:
        from sentence_transformers import SentenceTransformer
        import faiss
        rag_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        # ë¹ˆ ì¸ë±ìŠ¤ ì´ˆê¸°í™” (384ì°¨ì›)
        rag_index = faiss.IndexFlatIP(384)
        rag_enabled = True
        print("âœ… RAG ì´ˆê¸°í™” ì™„ë£Œ (FAISS + SentenceTransformer)")
        # ë””ìŠ¤í¬ì— ì €ì¥ëœ ì¸ë±ìŠ¤/ë¬¸ì„œ ìë™ ë¡œë“œ ì‹œë„
        try:
            rag_load_from_disk()
        except Exception as e:
            print(f"RAG ìë™ ë¡œë“œ ê±´ë„ˆëœ€: {e}")
    except Exception as e:
        rag_enabled = False
        print(f"âš ï¸ RAG ì´ˆê¸°í™” ë¹„í™œì„±í™”: {e}")

def build_rag(docs: List[Dict[str, Any]]):
    """ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì„ë² ë”© â†’ ì¸ë±ìŠ¤ êµ¬ì¶•"""
    global rag_index, rag_documents
    if not rag_enabled or rag_model is None:
        return False
    try:
        import numpy as np
        texts = [d.get('text', '') for d in docs]
        emb = rag_model.encode(texts, normalize_embeddings=True)
        # ìƒˆ ì¸ë±ìŠ¤ ìƒì„± í›„ êµì²´
        import faiss
        index = faiss.IndexFlatIP(emb.shape[1])
        index.add(emb.astype('float32'))
        rag_index = index
        rag_documents = docs
        return True
    except Exception as e:
        print(f"RAG ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨: {e}")
        return False

def rag_search(query: str, top_k: int = 5) -> List[Dict[str, Any]]:
    if not rag_enabled or rag_model is None or rag_index is None:
        return []
    try:
        import numpy as np
        q = rag_model.encode([query], normalize_embeddings=True).astype('float32')
        D, I = rag_index.search(q, top_k)
        results: List[Dict[str, Any]] = []
        for idx, score in zip(I[0], D[0]):
            if 0 <= idx < len(rag_documents):
                doc = rag_documents[idx].copy()
                doc['score'] = float(score)
                results.append(doc)
        return results
    except Exception as e:
        print(f"RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

def rag_save_to_disk() -> bool:
    """rag_indexì™€ rag_documentsë¥¼ ë””ìŠ¤í¬ì— ì €ì¥"""
    if not rag_enabled or rag_index is None:
        return False
    try:
        os.makedirs(RAG_DIR, exist_ok=True)
        # ë¬¸ì„œ ì €ì¥
        docs_path = os.path.join(RAG_DIR, 'rag_docs.json')
        with open(docs_path, 'w', encoding='utf-8') as f:
            json.dump(rag_documents, f, ensure_ascii=False)
        # ì¸ë±ìŠ¤ ì €ì¥
        import faiss
        index_path = os.path.join(RAG_DIR, 'rag.index')
        faiss.write_index(rag_index, index_path)
        return True
    except Exception as e:
        print(f"RAG ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def rag_load_from_disk() -> bool:
    """rag_indexì™€ rag_documentsë¥¼ ë””ìŠ¤í¬ì—ì„œ ë¡œë“œ"""
    global rag_documents, rag_index
    try:
        docs_path = os.path.join(RAG_DIR, 'rag_docs.json')
        index_path = os.path.join(RAG_DIR, 'rag.index')
        if not (os.path.isfile(docs_path) and os.path.isfile(index_path)):
            return False
        with open(docs_path, 'r', encoding='utf-8') as f:
            rag_documents = json.load(f)
        import faiss
        rag_index = faiss.read_index(index_path)
        return True
    except Exception as e:
        print(f"RAG ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

@app.route('/health', methods=['GET'])
def health():
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "current_model": current_model,
        "available_models": {
            "gemini": gemini_client is not None,
            "openai": openai_client is not None,
            "claude": claude_client is not None
        }
    })

@app.route('/chat', methods=['POST'])
@require_valid_input
@track_user_activity
@measure_performance("Chat API")
def chat():
    try:
        data = request.json
        message = data.get('message', '')
        player_uuid = data.get('player_uuid', '')
        
        # ğŸ”§ ê°œì„ ëœ ëª¨ë“œíŒ© íƒ€ê²ŸíŒ…: ìˆ˜ë™ ì„¤ì • ìš°ì„ , ìë™ ê°ì§€ í´ë°±
        modpack_name, modpack_version = get_target_modpack(data)
        
        print(f"ğŸ¯ íƒ€ê²Ÿ ëª¨ë“œíŒ©: {modpack_name} v{modpack_version}")
        print(f"ğŸ“ ì§ˆë¬¸: {message[:100]}{'...' if len(message) > 100 else ''}")

        # ë§ˆì¸í¬ë˜í”„íŠ¸ ëª¨ë“œíŒ© ì»¨í…ìŠ¤íŠ¸ + RAG ì²¨ë¶€ (RAG ìš°ì„  ì‚¬ìš©)
        rag_snippets = []
        rag_hits_count = 0
        rag_used_chars = 0
        gcp_rag_results = []
        rag_debug_info = {
            'rag_attempted': True,
            'rag_priority': 'gcp_first',
            'fallback_reason': None
        }
        rag_system_used = "none"
        
        # 1. GCP RAG ì‹œìŠ¤í…œ ìš°ì„  ì‹œë„ (ê¸°ë³¸ê°’)
        if GCP_RAG_ENABLED and gcp_rag.is_enabled():
            try:
                print(f"ğŸ” GCP RAG ê²€ìƒ‰ ì‹œë„: '{message[:50]}...' for {modpack_name} v{modpack_version}")
                
                gcp_results = gcp_rag.search_documents(
                    query=message,
                    modpack_name=modpack_name,
                    modpack_version=modpack_version,
                    top_k=RAG_TOP_K,
                    min_score=0.6  # ì„ê³„ê°’ ë‚®ì¶¤ (ë” ë§ì€ ê²°ê³¼)
                )
                
                if gcp_results:
                    gcp_rag_results = gcp_results
                    rag_system_used = "gcp_rag"
                    
                    for result in gcp_results:
                        if rag_used_chars >= RAG_TOTAL_MAX_CHARS:
                            break
                        
                        src = result.get('doc_source', 'unknown')
                        txt = result.get('text', '').replace('\n', ' ').strip()
                        similarity = result.get('similarity', 0.0)
                        
                        if len(txt) > RAG_SNIPPET_MAX_CHARS:
                            txt = txt[:RAG_SNIPPET_MAX_CHARS] + ' â€¦'
                        
                        remaining = RAG_TOTAL_MAX_CHARS - rag_used_chars
                        if len(txt) > remaining:
                            if remaining < 50:
                                break
                            txt = txt[:remaining] + ' â€¦'
                        
                        rag_snippets.append(f"- [GCP-RAG:{similarity:.2f}] [ì¶œì²˜:{src}] {txt}")
                        rag_used_chars += len(txt)
                    
                    rag_hits_count = len(gcp_results)
                    rag_debug_info['gcp_rag'] = {
                        'used': True,
                        'results_count': len(gcp_results),
                        'results': gcp_results[:3],  # ìƒìœ„ 3ê°œë§Œ ë””ë²„ê·¸ìš©ìœ¼ë¡œ ì €ì¥
                        'total_chars': rag_used_chars
                    }
                    
                    print(f"âœ… GCP RAG ì„±ê³µ: {len(gcp_results)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨")
                    
                else:
                    # GCP RAGì—ì„œ ê²°ê³¼ ì—†ìŒ
                    rag_debug_info['fallback_reason'] = f"GCP RAGì—ì„œ '{modpack_name} v{modpack_version}' ëª¨ë“œíŒ© ë°ì´í„° ì—†ìŒ ë˜ëŠ” ê´€ë ¨ì„± ë‚®ìŒ"
                    rag_debug_info['gcp_rag'] = {
                        'used': True,
                        'results_count': 0,
                        'no_results_reason': 'No matching documents or low similarity scores'
                    }
                    print(f"âš ï¸ GCP RAG: '{modpack_name} v{modpack_version}' ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ")
                
            except Exception as e:
                error_msg = f"GCP RAG ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"
                print(f"âŒ {error_msg}")
                rag_debug_info['fallback_reason'] = error_msg
                rag_debug_info['gcp_rag'] = {
                    'used': False, 
                    'error': str(e),
                    'error_type': type(e).__name__
                }
        else:
            # GCP RAG ë¹„í™œì„±í™”ë¨
            rag_debug_info['fallback_reason'] = "GCP RAG ì‹œìŠ¤í…œ ë¹„í™œì„±í™”ë¨"
            rag_debug_info['gcp_rag'] = {
                'used': False,
                'disabled_reason': 'GCP_RAG_ENABLED=false or gcp_rag not initialized'
            }
            print("âš ï¸ GCP RAG ë¹„í™œì„±í™” ìƒíƒœ")
        
        # 2. GCP RAG ì‹¤íŒ¨/ê²°ê³¼ ì—†ìŒ ì‹œ ë¡œì»¬ RAG í´ë°±
        if not rag_snippets and rag_enabled:
            try:
                print("ğŸ”„ ë¡œì»¬ RAG í´ë°± ì‹œë„...")
                hits = rag_search(message, top_k=RAG_TOP_K)
                
                if hits:
                    rag_hits_count = len(hits)
                    rag_system_used = "local_rag"
                    
                    for h in hits:
                        if rag_used_chars >= RAG_TOTAL_MAX_CHARS:
                            break
                        src = h.get('source', '') or 'unknown'
                        txt = (h.get('text', '') or '').replace('\n', ' ').strip()
                        score = h.get('score', 0.0)
                        
                        if len(txt) > RAG_SNIPPET_MAX_CHARS:
                            txt = txt[:RAG_SNIPPET_MAX_CHARS] + ' â€¦'
                        remaining = RAG_TOTAL_MAX_CHARS - rag_used_chars
                        if len(txt) > remaining:
                            if remaining < 50:
                                break
                            txt = txt[:remaining] + ' â€¦'
                        rag_snippets.append(f"- [ë¡œì»¬-RAG:{score:.2f}] [ì¶œì²˜:{src}] {txt}")
                        rag_used_chars += len(txt)
                    
                    rag_debug_info['local_rag'] = {
                        'used': True,
                        'results_count': len(hits),
                        'fallback_from': 'gcp_rag',
                        'total_chars': rag_used_chars
                    }
                    
                    print(f"âœ… ë¡œì»¬ RAG í´ë°± ì„±ê³µ: {len(hits)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨")
                    
                else:
                    rag_debug_info['local_rag'] = {
                        'used': True,
                        'results_count': 0,
                        'no_results_reason': 'No matching documents in local index'
                    }
                    print("âš ï¸ ë¡œì»¬ RAGì—ì„œë„ ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ")
                    
            except Exception as e:
                error_msg = f"ë¡œì»¬ RAG í´ë°± ì˜¤ë¥˜: {str(e)}"
                print(f"âŒ {error_msg}")
                rag_debug_info['local_rag'] = {
                    'used': False,
                    'error': str(e),
                    'error_type': type(e).__name__
                }
        
        # 3. RAG ê²°ê³¼ ì—†ìœ¼ë©´ ì›¹ê²€ìƒ‰ë§Œ ì‚¬ìš©í•œë‹¤ëŠ” ì•Œë¦¼
        if not rag_snippets:
            rag_system_used = "web_search_only"
            if not rag_debug_info.get('fallback_reason'):
                rag_debug_info['fallback_reason'] = "ëª¨ë“  RAG ì‹œìŠ¤í…œì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ"
            print("âš ï¸ RAG ì‹œìŠ¤í…œ ê²°ê³¼ ì—†ìŒ - ì›¹ê²€ìƒ‰ë§Œ ì‚¬ìš©")
        
        rag_block = "\n".join(rag_snippets) if rag_snippets else "(ëª¨ë“œíŒ© ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ ì›¹ê²€ìƒ‰ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤)"

        context = f"""
ë‹¹ì‹ ì€ ë§ˆì¸í¬ë˜í”„íŠ¸ ëª¨ë“œíŒ© ì „ë¬¸ê°€ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
í˜„ì¬ ëª¨ë“œíŒ©: {modpack_name} v{modpack_version}

ì•„ë˜ëŠ” ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ì¼ë¶€ì…ë‹ˆë‹¤(í•„ìš” ì‹œë§Œ ì°¸ê³ ):
{rag_block}

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ì œì‘ë²•, ì•„ì´í…œ ì •ë³´, ëª¨ë“œ ì„¤ëª… ë“±ì„ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

        # ì„ íƒëœ ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±
        if current_model == "gemini" and gemini_client:
            try:
                # ì›¹ê²€ìƒ‰ ë„êµ¬ ì„¤ì •
                config = None
                if GEMINI_WEBSEARCH_ENABLED:
                    grounding_tool = types.Tool(google_search=types.GoogleSearch())
                    config = types.GenerateContentConfig(tools=[grounding_tool])
                
                full_message = context + "\n\nì‚¬ìš©ì: " + message + "\n\nìµœì‹  ì •ë³´ê°€ í•„ìš”í•˜ë‹¤ë©´ ì›¹ ê²€ìƒ‰ì„ í™œìš©í•´ì„œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."
                
                # ì›¹ê²€ìƒ‰ ì§€ì› ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±
                with track_model_usage("gemini-2.5-pro-web"):
                    if config is not None:
                        response = gemini_client.models.generate_content(
                            model=GEMINI_MODEL,
                            contents=full_message,
                            config=config
                        )
                    else:
                        response = gemini_client.models.generate_content(
                            model=GEMINI_MODEL,
                            contents=full_message
                        )
                    ai_response = response.text
            except Exception as e:
                print(f"Gemini ì›¹ê²€ìƒ‰ ëª¨ë“œ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë“œë¡œ í´ë°±: {e}")
                # ì›¹ê²€ìƒ‰ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ëª¨ë“œë¡œ í´ë°±
                try:
                    full_message = context + "\n\nì‚¬ìš©ì: " + message + "\n\nAI:"
                    response = gemini_client.models.generate_content(
                        model=GEMINI_MODEL,
                        contents=full_message
                    )
                    ai_response = response.text
                except Exception as e2:
                    ai_response = f"Gemini API ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e2)}"

        elif current_model == "openai" and openai_client:
            try:
                # 2025ë…„ ìµœì‹  OpenAI API ë°©ì‹
                response = openai_client.chat.completions.create(
                    model=OPENAI_MODEL_PRIMARY,  # í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥
                    messages=[
                        {"role": "system", "content": context},
                        {"role": "user", "content": message}
                    ],
                    max_tokens=1000,
                    temperature=0.7
                )
                ai_response = response.choices[0].message.content
            except Exception as e:
                print(f"OpenAI GPT-4o-mini ì‹¤íŒ¨, GPT-3.5-turboë¡œ í´ë°±: {e}")
                # í´ë°± ì‹œë„
                try:
                    response = openai_client.chat.completions.create(
                        model=OPENAI_MODEL_FALLBACK,
                        messages=[
                            {"role": "system", "content": context},
                            {"role": "user", "content": message}
                        ],
                        max_tokens=1000,
                        temperature=0.7
                    )
                    ai_response = response.choices[0].message.content
                except Exception as e2:
                    ai_response = "OpenAI API ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. í• ë‹¹ëŸ‰ì´ë‚˜ API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

        elif current_model == "claude" and claude_client:
            try:
                response = claude_client.messages.create(
                    model=CLAUDE_MODEL,  # í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥
                    max_tokens=1000,
                    messages=[
                        {"role": "user", "content": context + "\n\n" + message}
                    ]
                )
                ai_response = response.content[0].text
            except Exception as e:
                if "credit" in str(e).lower() or "billing" in str(e).lower():
                    ai_response = "Claude APIëŠ” ìœ ë£Œ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. í¬ë ˆë”§ì„ ì¶©ì „í•´ì£¼ì„¸ìš”."
                else:
                    ai_response = "Claude API ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

        else:
            ai_response = "í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. Gemini API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."

        return jsonify({
            "success": True,
            "response": ai_response,
            "model": current_model,
            "timestamp": datetime.now().isoformat(),
            "rag": {
                "enabled": rag_enabled,
                "gcp_enabled": GCP_RAG_ENABLED and gcp_rag.is_enabled(),
                "system_used": rag_system_used,  # ì‹¤ì œ ì‚¬ìš©ëœ RAG ì‹œìŠ¤í…œ
                "hits": rag_hits_count,
                "used": rag_hits_count > 0,
                "success": rag_hits_count > 0,  # RAG ì„±ê³µ ì—¬ë¶€
                "fallback_reason": rag_debug_info.get('fallback_reason'),  # í´ë°± ì´ìœ 
                "top_k": RAG_TOP_K,
                "snippet_max_chars": RAG_SNIPPET_MAX_CHARS,
                "total_max_chars": RAG_TOTAL_MAX_CHARS,
                "used_chars": rag_used_chars,
                "debug_info": rag_debug_info,
                "user_message": rag_debug_info.get('fallback_reason') if rag_hits_count == 0 else None
            },
            "websearch_enabled": GEMINI_WEBSEARCH_ENABLED
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/models', methods=['GET'])
def get_models():
    models = []
    
    if gemini_client:
        models.append({
            "id": "gemini",
            "name": "Gemini 2.5 Pro (ì›¹ê²€ìƒ‰ ì§€ì›)",
            "provider": "Google",
            "available": True,
            "current": current_model == "gemini"
        })
    
    if openai_client:
        models.append({
            "id": "openai",
            "name": "GPT-4o Mini / GPT-3.5 Turbo",
            "provider": "OpenAI",
            "available": True,
            "current": current_model == "openai"
        })
    
    if claude_client:
        models.append({
            "id": "claude",
            "name": "Claude 3.5 Sonnet",
            "provider": "Anthropic",
            "available": True,
            "current": current_model == "claude"
        })
    
    return jsonify({"models": models})

# ---------------- RAG ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸ ----------------
@app.route('/rag/build', methods=['POST'])
def rag_build():
    """ê°„ë‹¨í•œ RAG ì¸ë±ìŠ¤ êµ¬ì¶• API
    - ì…ë ¥ í˜•ì‹ 1: {"docs": [{"text": "...", "source": "..."}, ...]}
    - ì…ë ¥ í˜•ì‹ 2: {"modpack_name": "...", "modpack_version": "...", "docs": [...]} (ë©”íƒ€ í¬í•¨)
    """
    try:
        data = request.get_json(force=True) or {}
        docs = data.get('docs', [])
        if not isinstance(docs, list) or not docs:
            return jsonify({"success": False, "error": "docs ë¦¬ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400
        # ìµœì†Œ í•„ë“œ ë³´ì •
        normalized = []
        for d in docs:
            if isinstance(d, dict) and d.get('text'):
                normalized.append({
                    'text': d.get('text', ''),
                    'source': d.get('source', 'manual')
                })
        if not normalized:
            return jsonify({"success": False, "error": "ìœ íš¨í•œ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤"}), 400
        ok = build_rag(normalized)
        return jsonify({"success": ok, "count": len(normalized)})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/rag/status', methods=['GET'])
def rag_status():
    return jsonify({
        "enabled": rag_enabled,
        "documents": len(rag_documents),
        "model": bool(rag_model)
    })

@app.route('/rag/save', methods=['POST'])
def rag_save():
    ok = rag_save_to_disk()
    return jsonify({"success": ok})

@app.route('/rag/load', methods=['POST'])
def rag_load():
    ok = rag_load_from_disk()
    return jsonify({"success": ok})

@app.route('/models/switch', methods=['POST'])
def switch_model():
    global current_model
    try:
        data = request.json
        model_id = data.get('model_id', 'gemini')

        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì¸ì§€ í™•ì¸
        available_models = []
        if gemini_client:
            available_models.append('gemini')
        if openai_client:
            available_models.append('openai')
        if claude_client:
            available_models.append('claude')

        if model_id in available_models:
            current_model = model_id
            return jsonify({
                "success": True,
                "message": f"ëª¨ë¸ì´ {model_id}ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤."
            })
        else:
            return jsonify({
                "success": False,
                "error": "ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ì´ê±°ë‚˜ API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            }), 400

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/modpack/switch', methods=['POST'])
def api_modpack_switch():
    """ê°„ì†Œí™”ëœ ëª¨ë“œíŒ© ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸.
    í˜„ì¬ëŠ” ì‹¤ì œ ë¶„ì„ ëŒ€ì‹  ì…ë ¥ê°’ì„ ê²€ì¦í•˜ê³  ê¸°ë³¸ ë©”íŠ¸ë¦­ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    modpack_switch.shê°€ ê¸°ëŒ€í•˜ëŠ” í•„ë“œë¥¼ í¬í•¨í•´ ì„±ê³µì ìœ¼ë¡œ ë™ì‘í•˜ë„ë¡ ë§ì¶¥ë‹ˆë‹¤.
    """
    try:
        data = request.get_json(force=True) or {}
        modpack_path = data.get('modpack_path', '')
        modpack_name = data.get('modpack_name', 'unknown')
        modpack_version = data.get('modpack_version', '1.0')

        # ê°„ë‹¨í•œ ìœ íš¨ì„± ê²€ì‚¬
        if not modpack_name:
            return jsonify({"success": False, "error": "modpack_name is required"}), 400

        # ê°„ë‹¨ ìŠ¤ìº” + RAG ìë™ êµ¬ì¶•
        stats = {}
        built = False
        if modpack_path and os.path.isdir(modpack_path):
            scan = scan_modpack(modpack_path)
            docs = scan.get('docs', [])
            stats = scan.get('stats', {})
            if docs:
                built = build_rag(docs)

        # ë°˜í™˜ í¬ë§·ì€ ìŠ¤í¬ë¦½íŠ¸ê°€ íŒŒì‹±í•˜ëŠ” í‚¤ì™€ ì¼ì¹˜í•´ì•¼ í•¨
        result = {
            "success": True,
            "modpack": {
                "name": modpack_name,
                "version": modpack_version,
                "path": modpack_path,
            },
            "mods_count": stats.get('mods', 0),
            "recipes_count": stats.get('recipes', 0),
            "items_count": stats.get('kubejs', 0),
            "rag_built": built,
            "language_mappings_added": 0,
            "timestamp": datetime.now().isoformat()
        }
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/recipe/<item_name>', methods=['GET'])
def get_recipe(item_name):
    try:
        # í˜„ì¬ í™œì„± ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ ë ˆì‹œí”¼ ê²€ìƒ‰
        if current_model == "gemini" and gemini_client:
            try:
                # ì›¹ê²€ìƒ‰ ë„êµ¬ ì„¤ì •ìœ¼ë¡œ ìµœì‹  ë ˆì‹œí”¼ ì •ë³´ ê²€ìƒ‰
                grounding_tool = types.Tool(google_search=types.GoogleSearch())
                config = types.GenerateContentConfig(tools=[grounding_tool])
                
                query = f"ë§ˆì¸í¬ë˜í”„íŠ¸ì—ì„œ {item_name}ì˜ ì œì‘ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”. ì¬ë£Œì™€ ì œì‘ ë°©ë²•ì„ í¬í•¨í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”. ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•´ì„œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."
                
                response = gemini_client.models.generate_content(
                    model=GEMINI_MODEL,
                    contents=query,
                    config=config
                )
                recipe_text = response.text
            except Exception as e:
                print(f"Gemini ì›¹ê²€ìƒ‰ ë ˆì‹œí”¼ ê²€ìƒ‰ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë“œë¡œ í´ë°±: {e}")
                # í´ë°±: ê²€ìƒ‰ ì—†ì´ ë ˆì‹œí”¼ ìƒì„±
                try:
                    query = f"ë§ˆì¸í¬ë˜í”„íŠ¸ì—ì„œ {item_name}ì˜ ì œì‘ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”. ì¬ë£Œì™€ ì œì‘ ë°©ë²•ì„ í¬í•¨í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."
                    response = gemini_client.models.generate_content(
                        model=GEMINI_MODEL,
                        contents=query
                    )
                    recipe_text = response.text
                except:
                    recipe_text = f"{item_name}ì˜ ì œì‘ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²Œì„ ë‚´ ì œì‘ë²• ì±…ì„ í™•ì¸í•´ë³´ì„¸ìš”."
        
        elif current_model == "openai" and openai_client:
            try:
                query = f"ë§ˆì¸í¬ë˜í”„íŠ¸ì—ì„œ {item_name}ì˜ ì œì‘ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”. ì¬ë£Œì™€ ì œì‘ ë°©ë²•ì„ í¬í•¨í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."
                response = openai_client.chat.completions.create(
                    model=OPENAI_MODEL_PRIMARY,
                    messages=[{"role": "user", "content": query}],
                    max_tokens=500,
                    temperature=0.7
                )
                recipe_text = response.choices[0].message.content
            except:
                recipe_text = f"{item_name}ì˜ ì œì‘ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²Œì„ ë‚´ ì œì‘ë²• ì±…ì„ í™•ì¸í•´ë³´ì„¸ìš”."
        
        elif current_model == "claude" and claude_client:
            try:
                query = f"ë§ˆì¸í¬ë˜í”„íŠ¸ì—ì„œ {item_name}ì˜ ì œì‘ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”. ì¬ë£Œì™€ ì œì‘ ë°©ë²•ì„ í¬í•¨í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."
                response = claude_client.messages.create(
                    model=CLAUDE_MODEL,
                    max_tokens=500,
                    messages=[{"role": "user", "content": query}]
                )
                recipe_text = response.content[0].text
            except:
                recipe_text = f"{item_name}ì˜ ì œì‘ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²Œì„ ë‚´ ì œì‘ë²• ì±…ì„ í™•ì¸í•´ë³´ì„¸ìš”."
        else:
            recipe_text = f"{item_name}ì˜ ì œì‘ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²Œì„ ë‚´ ì œì‘ë²• ì±…ì„ í™•ì¸í•´ë³´ì„¸ìš”."

        # 3x3 ë ˆì‹œí”¼ êµ¬ì¡°(ìˆìœ¼ë©´ AI ì‘ë‹µ íŒŒì‹±, ê¸°ë³¸ì€ í…ìŠ¤íŠ¸ë§Œ)
        recipe_info = {
            "item": item_name,
            "recipe": recipe_text,
            "grid": [[None, None, None], [None, None, None], [None, None, None]],
            "materials": [],
            "crafting_type": "crafting_table"
        }

        return jsonify({
            "success": True,
            "recipe": recipe_info
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

# =============== GCP RAG ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸ ===============

@app.route('/gcp-rag/build', methods=['POST'])
def gcp_rag_build():
    """GCP RAG ì¸ë±ìŠ¤ êµ¬ì¶•"""
    try:
        data = request.get_json(force=True) or {}
        modpack_name = data.get('modpack_name', '').strip()
        modpack_version = data.get('modpack_version', '1.0.0').strip()
        modpack_path = data.get('modpack_path', '').strip()
        
        if not all([modpack_name, modpack_version, modpack_path]):
            return jsonify({
                "success": False, 
                "error": "modpack_name, modpack_version, modpack_path ëª¨ë‘ í•„ìš”"
            }), 400
        
        if not gcp_rag.is_enabled():
            return jsonify({
                "success": False,
                "error": "GCP RAG ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. GCP_PROJECT_ID í™˜ê²½ë³€ìˆ˜ì™€ ì¸ì¦ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”."
            }), 503
        
        # ë¹„ë™ê¸°ì ìœ¼ë¡œ ì¸ë±ìŠ¤ êµ¬ì¶• (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” Celery ë“± ì‚¬ìš© ê¶Œì¥)
        result = gcp_rag.build_modpack_index(modpack_name, modpack_version, modpack_path)
        return jsonify(result)
        
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/gcp-rag/search', methods=['POST'])
def gcp_rag_search():
    """GCP RAG ê²€ìƒ‰ (ë””ë²„ê·¸ìš© - ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ í™•ì¸)"""
    try:
        data = request.get_json(force=True) or {}
        query = data.get('query', '').strip()
        modpack_name = data.get('modpack_name', '').strip()
        modpack_version = data.get('modpack_version', '1.0.0').strip()
        top_k = min(data.get('top_k', 5), 20)  # ìµœëŒ€ 20ê°œ
        min_score = max(0.0, min(1.0, data.get('min_score', 0.7)))
        
        if not all([query, modpack_name, modpack_version]):
            return jsonify({
                "success": False,
                "error": "query, modpack_name, modpack_version ëª¨ë‘ í•„ìš”"
            }), 400
        
        if not gcp_rag.is_enabled():
            return jsonify({
                "success": False,
                "error": "GCP RAG ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
            }), 503
        
        results = gcp_rag.search_documents(
            query=query,
            modpack_name=modpack_name,
            modpack_version=modpack_version,
            top_k=top_k,
            min_score=min_score
        )
        
        return jsonify({
            "success": True,
            "query": query,
            "modpack": f"{modpack_name} v{modpack_version}",
            "results_count": len(results),
            "results": results,
            "search_params": {
                "top_k": top_k,
                "min_score": min_score
            }
        })
        
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/gcp-rag/modpacks', methods=['GET'])
def gcp_rag_modpacks():
    """ë“±ë¡ëœ ëª¨ë“œíŒ© ëª©ë¡"""
    try:
        if not gcp_rag.is_enabled():
            return jsonify({
                "success": False,
                "error": "GCP RAG ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
            }), 503
        
        modpacks = gcp_rag.get_modpack_list()
        return jsonify({
            "success": True,
            "modpacks": modpacks,
            "count": len(modpacks)
        })
        
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/gcp-rag/delete', methods=['DELETE'])
def gcp_rag_delete():
    """GCP RAG ì¸ë±ìŠ¤ ì‚­ì œ"""
    try:
        data = request.get_json(force=True) or {}
        modpack_name = data.get('modpack_name', '').strip()
        modpack_version = data.get('modpack_version', '1.0.0').strip()
        
        if not all([modpack_name, modpack_version]):
            return jsonify({
                "success": False,
                "error": "modpack_name, modpack_version ëª¨ë‘ í•„ìš”"
            }), 400
        
        if not gcp_rag.is_enabled():
            return jsonify({
                "success": False,
                "error": "GCP RAG ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
            }), 503
        
        success = gcp_rag.delete_modpack_index(modpack_name, modpack_version)
        return jsonify({
            "success": success,
            "message": f"{modpack_name} v{modpack_version} ì¸ë±ìŠ¤ ì‚­ì œ {'ì™„ë£Œ' if success else 'ì‹¤íŒ¨'}"
        })
        
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/gcp-rag/status', methods=['GET'])
def gcp_rag_status():
    """GCP RAG ì‹œìŠ¤í…œ ìƒíƒœ"""
    try:
        return jsonify({
            "success": True,
            "gcp_rag_enabled": GCP_RAG_ENABLED,
            "gcp_rag_available": gcp_rag.is_enabled(),
            "project_id": gcp_rag.project_id if gcp_rag.is_enabled() else None,
            "location": gcp_rag.location if gcp_rag.is_enabled() else None,
            "local_rag_enabled": rag_enabled
        })
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

if __name__ == '__main__':
    print("ğŸš€ ë§ˆì¸í¬ë˜í”„íŠ¸ AI ë°±ì—”ë“œ ì‹œì‘ ì¤‘...")
    print(f"ğŸ“Š í˜„ì¬ í™œì„± ëª¨ë¸: {current_model if current_model else 'ì—†ìŒ'}")
    print(f"ğŸ”‘ Google API (Gemini): {'âœ…' if gemini_client else 'âŒ'}")
    print(f"ğŸ”‘ OpenAI API: {'âœ…' if openai_client else 'âŒ'}")  
    print(f"ğŸ”‘ Anthropic API (Claude): {'âœ…' if claude_client else 'âŒ'}")
    print(f"ğŸ”— GCP RAG: {'âœ…' if GCP_RAG_ENABLED and gcp_rag.is_enabled() else 'âŒ'}")
    
    if current_model:
        print(f"ğŸ¯ ì£¼ ì‚¬ìš© ëª¨ë¸: {current_model}")
        if current_model == "gemini":
            print("ğŸŒ Gemini ì›¹ê²€ìƒ‰ ê¸°ëŠ¥ í™œì„±í™”ë¨")
    else:
        print("âš ï¸ ê²½ê³ : ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
        print("ğŸ’¡ ìµœì†Œí•œ Google API í‚¤(Gemini)ë¥¼ ì„¤ì •í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
    
    if GCP_RAG_ENABLED and gcp_rag.is_enabled():
        print("ğŸ¯ GCP RAG í™œì„±í™”ë¨ - ëª¨ë“œíŒ©ë³„ ë²¡í„° ê²€ìƒ‰ ê°€ëŠ¥")
        modpack_count = len(gcp_rag.get_modpack_list())
        print(f"ğŸ“¦ ë“±ë¡ëœ ëª¨ë“œíŒ©: {modpack_count}ê°œ")
    elif GCP_RAG_ENABLED:
        print("âš ï¸ GCP RAG ì„¤ì • ë¶ˆì™„ì „ - GCP_PROJECT_IDì™€ ì¸ì¦ í™•ì¸ í•„ìš”")
    else:
        print("ğŸ“ GCP RAG ë¹„í™œì„±í™” - ë¡œì»¬ RAGë§Œ ì‚¬ìš©")
    
    print("=" * 60)
    init_rag()
    app.run(host='0.0.0.0', port=5000, debug=False)