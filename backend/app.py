from flask import Flask, request, jsonify
from flask_cors import CORS
import os
import json
import requests
from datetime import datetime
from dotenv import load_dotenv

# ìƒˆë¡œìš´ Gemini SDK
from google import genai
from google.genai import types

# ë³´ì•ˆ ë° ëª¨ë‹ˆí„°ë§ ë¯¸ë“¤ì›¨ì–´
from middleware.security import SecurityMiddleware, require_valid_input, measure_performance
from middleware.monitoring import MonitoringMiddleware, track_model_usage, track_user_activity

load_dotenv()

app = Flask(__name__)
CORS(app)

# ë¯¸ë“¤ì›¨ì–´ ì´ˆê¸°í™”
security_middleware = SecurityMiddleware(app)
monitoring_middleware = MonitoringMiddleware(app)

# API í‚¤ ì„¤ì •
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')

# AI ëª¨ë¸ ì´ˆê¸°í™” (ì•ˆì „í•˜ê²Œ)
gemini_client = None
openai_client = None
claude_client = None

# Google AI ì´ˆê¸°í™” - 2025ë…„ ìµœì‹  SDK ë° ì›¹ê²€ìƒ‰ ì§€ì›
if GOOGLE_API_KEY:
    try:
        gemini_client = genai.Client(api_key=GOOGLE_API_KEY)
        print("âœ… Gemini 2.5 Pro í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ì›¹ê²€ìƒ‰ ì§€ì›, google-genai SDK)")
    except Exception as e:
        print(f"âš ï¸ Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        gemini_client = None

# OpenAI ì´ˆê¸°í™” - 2025ë…„ ì—…ë°ì´íŠ¸ëœ ë°©ì‹, ì•ˆì „í•œ ì²˜ë¦¬
if OPENAI_API_KEY and OPENAI_API_KEY != "dummy" and len(OPENAI_API_KEY) > 10:
    try:
        # ìƒˆë¡œìš´ OpenAI í´ë¼ì´ì–¸íŠ¸ ë°©ì‹
        from openai import OpenAI
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
        
        # API í‚¤ ìœ íš¨ì„± ê°„ë‹¨ í…ŒìŠ¤íŠ¸ (ë¹„ìš© ìµœì†Œí™”)
        test_response = openai_client.models.list()
        print("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ë¬´ë£Œ í‹°ì–´)")
    except Exception as e:
        print(f"âš ï¸ OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        openai_client = None
elif OPENAI_API_KEY:
    print("âš ï¸ OpenAI API í‚¤ê°€ ë”ë¯¸ ê°’ì´ê±°ë‚˜ ë„ˆë¬´ ì§§ì•„ì„œ ë¹„í™œì„±í™”ë¨")

# Anthropic ì´ˆê¸°í™” - ì•ˆì „í•œ ì²˜ë¦¬ (ë¬´ë£Œ í‹°ì–´ ì—†ìŒ)
if ANTHROPIC_API_KEY and ANTHROPIC_API_KEY != "dummy" and len(ANTHROPIC_API_KEY) > 10:
    try:
        import anthropic
        claude_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
        
        # API í‚¤ ìœ íš¨ì„± ê°„ë‹¨ í…ŒìŠ¤íŠ¸
        claude_client.models.list()
        print("âœ… Claude í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ìœ ë£Œ API)")
    except Exception as e:
        print(f"âš ï¸ Claude API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        claude_client = None
elif ANTHROPIC_API_KEY:
    print("âš ï¸ Anthropic API í‚¤ê°€ ë”ë¯¸ ê°’ì´ê±°ë‚˜ ë„ˆë¬´ ì§§ì•„ì„œ ë¹„í™œì„±í™”ë¨")

# í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ (ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ëª¨ë¸ ì„ íƒ, Gemini ìš°ì„ )
current_model = "gemini" if gemini_client else "openai" if openai_client else "claude" if claude_client else None

@app.route('/health', methods=['GET'])
def health():
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "current_model": current_model,
        "available_models": {
            "gemini": gemini_client is not None,
            "openai": openai_client is not None,
            "claude": claude_client is not None
        }
    })

@app.route('/chat', methods=['POST'])
@require_valid_input
@track_user_activity
@measure_performance("Chat API")
def chat():
    try:
        data = request.json
        message = data.get('message', '')
        player_uuid = data.get('player_uuid', '')
        modpack_name = data.get('modpack_name', 'Unknown Modpack')
        modpack_version = data.get('modpack_version', '1.0.0')

        # ë§ˆì¸í¬ë˜í”„íŠ¸ ëª¨ë“œíŒ© ì»¨í…ìŠ¤íŠ¸
        context = f"""
ë‹¹ì‹ ì€ ë§ˆì¸í¬ë˜í”„íŠ¸ ëª¨ë“œíŒ© ì „ë¬¸ê°€ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
í˜„ì¬ ëª¨ë“œíŒ©: {modpack_name} v{modpack_version}

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ì œì‘ë²•, ì•„ì´í…œ ì •ë³´, ëª¨ë“œ ì„¤ëª… ë“±ì„ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

        # ì„ íƒëœ ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±
        if current_model == "gemini" and gemini_client:
            try:
                # ì›¹ê²€ìƒ‰ ë„êµ¬ ì„¤ì •
                grounding_tool = types.Tool(google_search=types.GoogleSearch())
                config = types.GenerateContentConfig(tools=[grounding_tool])
                
                full_message = context + "\n\nì‚¬ìš©ì: " + message + "\n\nìµœì‹  ì •ë³´ê°€ í•„ìš”í•˜ë‹¤ë©´ ì›¹ ê²€ìƒ‰ì„ í™œìš©í•´ì„œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."
                
                # ì›¹ê²€ìƒ‰ ì§€ì› ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±
                with track_model_usage("gemini-2.5-pro-web"):
                    response = gemini_client.models.generate_content(
                        model="gemini-2.5-pro",
                        contents=full_message,
                        config=config
                    )
                    ai_response = response.text
            except Exception as e:
                print(f"Gemini ì›¹ê²€ìƒ‰ ëª¨ë“œ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë“œë¡œ í´ë°±: {e}")
                # ì›¹ê²€ìƒ‰ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ëª¨ë“œë¡œ í´ë°±
                try:
                    full_message = context + "\n\nì‚¬ìš©ì: " + message + "\n\nAI:"
                    response = gemini_client.models.generate_content(
                        model="gemini-2.5-pro",
                        contents=full_message
                    )
                    ai_response = response.text
                except Exception as e2:
                    ai_response = f"Gemini API ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e2)}"

        elif current_model == "openai" and openai_client:
            try:
                # 2025ë…„ ìµœì‹  OpenAI API ë°©ì‹
                response = openai_client.chat.completions.create(
                    model="gpt-4o-mini",  # ë¬´ë£Œ í‹°ì–´ ìµœì‹  ëª¨ë¸
                    messages=[
                        {"role": "system", "content": context},
                        {"role": "user", "content": message}
                    ],
                    max_tokens=1000,
                    temperature=0.7
                )
                ai_response = response.choices[0].message.content
            except Exception as e:
                print(f"OpenAI GPT-4o-mini ì‹¤íŒ¨, GPT-3.5-turboë¡œ í´ë°±: {e}")
                # í´ë°± ì‹œë„
                try:
                    response = openai_client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role": "system", "content": context},
                            {"role": "user", "content": message}
                        ],
                        max_tokens=1000,
                        temperature=0.7
                    )
                    ai_response = response.choices[0].message.content
                except Exception as e2:
                    ai_response = "OpenAI API ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. í• ë‹¹ëŸ‰ì´ë‚˜ API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

        elif current_model == "claude" and claude_client:
            try:
                response = claude_client.messages.create(
                    model="claude-3-5-sonnet-20241022",  # 2025ë…„ ìµœì‹  Claude ëª¨ë¸
                    max_tokens=1000,
                    messages=[
                        {"role": "user", "content": context + "\n\n" + message}
                    ]
                )
                ai_response = response.content[0].text
            except Exception as e:
                if "credit" in str(e).lower() or "billing" in str(e).lower():
                    ai_response = "Claude APIëŠ” ìœ ë£Œ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. í¬ë ˆë”§ì„ ì¶©ì „í•´ì£¼ì„¸ìš”."
                else:
                    ai_response = "Claude API ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

        else:
            ai_response = "í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. Gemini API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."

        return jsonify({
            "success": True,
            "response": ai_response,
            "model": current_model,
            "timestamp": datetime.now().isoformat()
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/models', methods=['GET'])
def get_models():
    models = []
    
    if gemini_client:
        models.append({
            "id": "gemini",
            "name": "Gemini 2.5 Pro (ì›¹ê²€ìƒ‰ ì§€ì›)",
            "provider": "Google",
            "available": True,
            "current": current_model == "gemini"
        })
    
    if openai_client:
        models.append({
            "id": "openai",
            "name": "GPT-4o Mini / GPT-3.5 Turbo",
            "provider": "OpenAI",
            "available": True,
            "current": current_model == "openai"
        })
    
    if claude_client:
        models.append({
            "id": "claude",
            "name": "Claude 3.5 Sonnet",
            "provider": "Anthropic",
            "available": True,
            "current": current_model == "claude"
        })
    
    return jsonify({"models": models})

@app.route('/models/switch', methods=['POST'])
def switch_model():
    global current_model
    try:
        data = request.json
        model_id = data.get('model_id', 'gemini')

        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì¸ì§€ í™•ì¸
        available_models = []
        if gemini_client:
            available_models.append('gemini')
        if openai_client:
            available_models.append('openai')
        if claude_client:
            available_models.append('claude')

        if model_id in available_models:
            current_model = model_id
            return jsonify({
                "success": True,
                "message": f"ëª¨ë¸ì´ {model_id}ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤."
            })
        else:
            return jsonify({
                "success": False,
                "error": "ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ì´ê±°ë‚˜ API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            }), 400

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/recipe/<item_name>', methods=['GET'])
def get_recipe(item_name):
    try:
        # í˜„ì¬ í™œì„± ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ ë ˆì‹œí”¼ ê²€ìƒ‰
        if current_model == "gemini" and gemini_client:
            try:
                # ì›¹ê²€ìƒ‰ ë„êµ¬ ì„¤ì •ìœ¼ë¡œ ìµœì‹  ë ˆì‹œí”¼ ì •ë³´ ê²€ìƒ‰
                grounding_tool = types.Tool(google_search=types.GoogleSearch())
                config = types.GenerateContentConfig(tools=[grounding_tool])
                
                query = f"ë§ˆì¸í¬ë˜í”„íŠ¸ì—ì„œ {item_name}ì˜ ì œì‘ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”. ì¬ë£Œì™€ ì œì‘ ë°©ë²•ì„ í¬í•¨í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”. ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•´ì„œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."
                
                response = gemini_client.models.generate_content(
                    model="gemini-2.5-pro",
                    contents=query,
                    config=config
                )
                recipe_text = response.text
            except Exception as e:
                print(f"Gemini ì›¹ê²€ìƒ‰ ë ˆì‹œí”¼ ê²€ìƒ‰ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë“œë¡œ í´ë°±: {e}")
                # í´ë°±: ê²€ìƒ‰ ì—†ì´ ë ˆì‹œí”¼ ìƒì„±
                try:
                    query = f"ë§ˆì¸í¬ë˜í”„íŠ¸ì—ì„œ {item_name}ì˜ ì œì‘ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”. ì¬ë£Œì™€ ì œì‘ ë°©ë²•ì„ í¬í•¨í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."
                    response = gemini_client.models.generate_content(
                        model="gemini-2.5-pro",
                        contents=query
                    )
                    recipe_text = response.text
                except:
                    recipe_text = f"{item_name}ì˜ ì œì‘ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²Œì„ ë‚´ ì œì‘ë²• ì±…ì„ í™•ì¸í•´ë³´ì„¸ìš”."
        
        elif current_model == "openai" and openai_client:
            try:
                query = f"ë§ˆì¸í¬ë˜í”„íŠ¸ì—ì„œ {item_name}ì˜ ì œì‘ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”. ì¬ë£Œì™€ ì œì‘ ë°©ë²•ì„ í¬í•¨í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."
                response = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": query}],
                    max_tokens=500,
                    temperature=0.7
                )
                recipe_text = response.choices[0].message.content
            except:
                recipe_text = f"{item_name}ì˜ ì œì‘ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²Œì„ ë‚´ ì œì‘ë²• ì±…ì„ í™•ì¸í•´ë³´ì„¸ìš”."
        
        elif current_model == "claude" and claude_client:
            try:
                query = f"ë§ˆì¸í¬ë˜í”„íŠ¸ì—ì„œ {item_name}ì˜ ì œì‘ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”. ì¬ë£Œì™€ ì œì‘ ë°©ë²•ì„ í¬í•¨í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."
                response = claude_client.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=500,
                    messages=[{"role": "user", "content": query}]
                )
                recipe_text = response.content[0].text
            except:
                recipe_text = f"{item_name}ì˜ ì œì‘ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²Œì„ ë‚´ ì œì‘ë²• ì±…ì„ í™•ì¸í•´ë³´ì„¸ìš”."
        else:
            recipe_text = f"{item_name}ì˜ ì œì‘ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²Œì„ ë‚´ ì œì‘ë²• ì±…ì„ í™•ì¸í•´ë³´ì„¸ìš”."

        recipe_info = {
            "item": item_name,
            "recipe": recipe_text,
            "materials": [],
            "crafting_type": "unknown"
        }

        return jsonify({
            "success": True,
            "recipe": recipe_info
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

if __name__ == '__main__':
    print("ğŸš€ ë§ˆì¸í¬ë˜í”„íŠ¸ AI ë°±ì—”ë“œ ì‹œì‘ ì¤‘...")
    print(f"ğŸ“Š í˜„ì¬ í™œì„± ëª¨ë¸: {current_model if current_model else 'ì—†ìŒ'}")
    print(f"ğŸ”‘ Google API (Gemini): {'âœ…' if gemini_client else 'âŒ'}")
    print(f"ğŸ”‘ OpenAI API: {'âœ…' if openai_client else 'âŒ'}")  
    print(f"ğŸ”‘ Anthropic API (Claude): {'âœ…' if claude_client else 'âŒ'}")
    
    if current_model:
        print(f"ğŸ¯ ì£¼ ì‚¬ìš© ëª¨ë¸: {current_model}")
        if current_model == "gemini":
            print("ğŸŒ Gemini ì›¹ê²€ìƒ‰ ê¸°ëŠ¥ í™œì„±í™”ë¨")
    else:
        print("âš ï¸ ê²½ê³ : ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
        print("ğŸ’¡ ìµœì†Œí•œ Google API í‚¤(Gemini)ë¥¼ ì„¤ì •í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
    
    print("=" * 60)
    app.run(host='0.0.0.0', port=5000, debug=False) 