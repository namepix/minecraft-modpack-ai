from flask import Flask, request, jsonify
from flask_cors import CORS
import os
import json
import requests
from datetime import datetime
from dotenv import load_dotenv
from typing import List, Dict, Any

# ìƒˆë¡œìš´ Gemini SDK
from google import genai
from google.genai import types

# ë³´ì•ˆ ë° ëª¨ë‹ˆí„°ë§ ë¯¸ë“¤ì›¨ì–´
from middleware.security import SecurityMiddleware, require_valid_input, measure_performance
from middleware.monitoring import MonitoringMiddleware, track_model_usage, track_user_activity
from modpack_parser import scan_modpack

load_dotenv()

app = Flask(__name__)
CORS(app)

# ë¯¸ë“¤ì›¨ì–´ ì´ˆê¸°í™”
security_middleware = SecurityMiddleware(app)
monitoring_middleware = MonitoringMiddleware(app)

# API í‚¤ ì„¤ì •
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')
GEMINI_WEBSEARCH_ENABLED = os.getenv('GEMINI_WEBSEARCH_ENABLED', 'true').lower() == 'true'

# ëª¨ë¸ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥)
GEMINI_MODEL = os.getenv('GEMINI_MODEL', 'gemini-2.5-pro')
OPENAI_MODEL_PRIMARY = os.getenv('OPENAI_MODEL_PRIMARY', 'gpt-4o-mini')
OPENAI_MODEL_FALLBACK = os.getenv('OPENAI_MODEL_FALLBACK', 'gpt-3.5-turbo')
CLAUDE_MODEL = os.getenv('CLAUDE_MODEL', 'claude-3-5-sonnet-20241022')
# RAG í”„ë¡¬í”„íŠ¸ ì²¨ë¶€ ì˜ˆì‚°(í™˜ê²½ë³€ìˆ˜ë¡œ ì¡°ì • ê°€ëŠ¥)
RAG_TOP_K = int(os.getenv('RAG_TOP_K', '5'))
RAG_SNIPPET_MAX_CHARS = int(os.getenv('RAG_SNIPPET_MAX_CHARS', '500'))
RAG_TOTAL_MAX_CHARS = int(os.getenv('RAG_TOTAL_MAX_CHARS', '1500'))

# AI ëª¨ë¸ ì´ˆê¸°í™” (ì•ˆì „í•˜ê²Œ)
gemini_client = None
openai_client = None
claude_client = None

# Google AI ì´ˆê¸°í™” - 2025ë…„ ìµœì‹  SDK ë° ì›¹ê²€ìƒ‰ ì§€ì›
if GOOGLE_API_KEY:
    try:
        gemini_client = genai.Client(api_key=GOOGLE_API_KEY)
        print("âœ… Gemini 2.5 Pro í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ì›¹ê²€ìƒ‰ ì§€ì›, google-genai SDK)")
    except Exception as e:
        print(f"âš ï¸ Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        gemini_client = None

# OpenAI ì´ˆê¸°í™” - 2025ë…„ ì—…ë°ì´íŠ¸ëœ ë°©ì‹, ì•ˆì „í•œ ì²˜ë¦¬
if OPENAI_API_KEY and OPENAI_API_KEY != "dummy" and len(OPENAI_API_KEY) > 10:
    try:
        # ìƒˆë¡œìš´ OpenAI í´ë¼ì´ì–¸íŠ¸ ë°©ì‹
        from openai import OpenAI
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
        
        # API í‚¤ ìœ íš¨ì„± ê°„ë‹¨ í…ŒìŠ¤íŠ¸ (ë¹„ìš© ìµœì†Œí™”)
        test_response = openai_client.models.list()
        print("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ë¬´ë£Œ í‹°ì–´)")
    except Exception as e:
        print(f"âš ï¸ OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        openai_client = None
elif OPENAI_API_KEY:
    print("âš ï¸ OpenAI API í‚¤ê°€ ë”ë¯¸ ê°’ì´ê±°ë‚˜ ë„ˆë¬´ ì§§ì•„ì„œ ë¹„í™œì„±í™”ë¨")

# Anthropic ì´ˆê¸°í™” - ì•ˆì „í•œ ì²˜ë¦¬ (ë¬´ë£Œ í‹°ì–´ ì—†ìŒ)
if ANTHROPIC_API_KEY and ANTHROPIC_API_KEY != "dummy" and len(ANTHROPIC_API_KEY) > 10:
    try:
        import anthropic
        claude_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
        
        # API í‚¤ ìœ íš¨ì„± ê°„ë‹¨ í…ŒìŠ¤íŠ¸
        claude_client.models.list()
        print("âœ… Claude í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ìœ ë£Œ API)")
    except Exception as e:
        print(f"âš ï¸ Claude API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        claude_client = None
elif ANTHROPIC_API_KEY:
    print("âš ï¸ Anthropic API í‚¤ê°€ ë”ë¯¸ ê°’ì´ê±°ë‚˜ ë„ˆë¬´ ì§§ì•„ì„œ ë¹„í™œì„±í™”ë¨")

# í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ (ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ëª¨ë¸ ì„ íƒ, Gemini ìš°ì„ )
current_model = "gemini" if gemini_client else "openai" if openai_client else "claude" if claude_client else None

# ========= ê°„ë‹¨ RAG ì»´í¬ë„ŒíŠ¸ (FAISS + SentenceTransformer) =========
rag_enabled = False
rag_index = None
rag_documents: List[Dict[str, Any]] = []
rag_model = None

RAG_DIR = os.path.join(os.path.expanduser('~'), 'minecraft-ai-backend', 'rag')

def init_rag():
    global rag_enabled, rag_index, rag_model
    try:
        from sentence_transformers import SentenceTransformer
        import faiss
        rag_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        # ë¹ˆ ì¸ë±ìŠ¤ ì´ˆê¸°í™” (384ì°¨ì›)
        rag_index = faiss.IndexFlatIP(384)
        rag_enabled = True
        print("âœ… RAG ì´ˆê¸°í™” ì™„ë£Œ (FAISS + SentenceTransformer)")
        # ë””ìŠ¤í¬ì— ì €ì¥ëœ ì¸ë±ìŠ¤/ë¬¸ì„œ ìë™ ë¡œë“œ ì‹œë„
        try:
            rag_load_from_disk()
        except Exception as e:
            print(f"RAG ìë™ ë¡œë“œ ê±´ë„ˆëœ€: {e}")
    except Exception as e:
        rag_enabled = False
        print(f"âš ï¸ RAG ì´ˆê¸°í™” ë¹„í™œì„±í™”: {e}")

def build_rag(docs: List[Dict[str, Any]]):
    """ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì„ë² ë”© â†’ ì¸ë±ìŠ¤ êµ¬ì¶•"""
    global rag_index, rag_documents
    if not rag_enabled or rag_model is None:
        return False
    try:
        import numpy as np
        texts = [d.get('text', '') for d in docs]
        emb = rag_model.encode(texts, normalize_embeddings=True)
        # ìƒˆ ì¸ë±ìŠ¤ ìƒì„± í›„ êµì²´
        import faiss
        index = faiss.IndexFlatIP(emb.shape[1])
        index.add(emb.astype('float32'))
        rag_index = index
        rag_documents = docs
        return True
    except Exception as e:
        print(f"RAG ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨: {e}")
        return False

def rag_search(query: str, top_k: int = 5) -> List[Dict[str, Any]]:
    if not rag_enabled or rag_model is None or rag_index is None:
        return []
    try:
        import numpy as np
        q = rag_model.encode([query], normalize_embeddings=True).astype('float32')
        D, I = rag_index.search(q, top_k)
        results: List[Dict[str, Any]] = []
        for idx, score in zip(I[0], D[0]):
            if 0 <= idx < len(rag_documents):
                doc = rag_documents[idx].copy()
                doc['score'] = float(score)
                results.append(doc)
        return results
    except Exception as e:
        print(f"RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

def rag_save_to_disk() -> bool:
    """rag_indexì™€ rag_documentsë¥¼ ë””ìŠ¤í¬ì— ì €ì¥"""
    if not rag_enabled or rag_index is None:
        return False
    try:
        os.makedirs(RAG_DIR, exist_ok=True)
        # ë¬¸ì„œ ì €ì¥
        docs_path = os.path.join(RAG_DIR, 'rag_docs.json')
        with open(docs_path, 'w', encoding='utf-8') as f:
            json.dump(rag_documents, f, ensure_ascii=False)
        # ì¸ë±ìŠ¤ ì €ì¥
        import faiss
        index_path = os.path.join(RAG_DIR, 'rag.index')
        faiss.write_index(rag_index, index_path)
        return True
    except Exception as e:
        print(f"RAG ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def rag_load_from_disk() -> bool:
    """rag_indexì™€ rag_documentsë¥¼ ë””ìŠ¤í¬ì—ì„œ ë¡œë“œ"""
    global rag_documents, rag_index
    try:
        docs_path = os.path.join(RAG_DIR, 'rag_docs.json')
        index_path = os.path.join(RAG_DIR, 'rag.index')
        if not (os.path.isfile(docs_path) and os.path.isfile(index_path)):
            return False
        with open(docs_path, 'r', encoding='utf-8') as f:
            rag_documents = json.load(f)
        import faiss
        rag_index = faiss.read_index(index_path)
        return True
    except Exception as e:
        print(f"RAG ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

@app.route('/health', methods=['GET'])
def health():
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "current_model": current_model,
        "available_models": {
            "gemini": gemini_client is not None,
            "openai": openai_client is not None,
            "claude": claude_client is not None
        }
    })

@app.route('/chat', methods=['POST'])
@require_valid_input
@track_user_activity
@measure_performance("Chat API")
def chat():
    try:
        data = request.json
        message = data.get('message', '')
        player_uuid = data.get('player_uuid', '')
        modpack_name = data.get('modpack_name', 'Unknown Modpack')
        modpack_version = data.get('modpack_version', '1.0.0')

        # ë§ˆì¸í¬ë˜í”„íŠ¸ ëª¨ë“œíŒ© ì»¨í…ìŠ¤íŠ¸ + RAG ì²¨ë¶€
        rag_snippets = []
        rag_hits_count = 0
        rag_used_chars = 0
        if rag_enabled:
            hits = rag_search(message, top_k=RAG_TOP_K)
            rag_hits_count = len(hits)
            for h in hits:
                if rag_used_chars >= RAG_TOTAL_MAX_CHARS:
                    break
                src = h.get('source', '') or 'unknown'
                txt = (h.get('text', '') or '').replace('\n', ' ').strip()
                if len(txt) > RAG_SNIPPET_MAX_CHARS:
                    txt = txt[:RAG_SNIPPET_MAX_CHARS] + ' â€¦'
                # ì´ëŸ‰ ì˜ˆì‚° ì²´í¬
                remaining = RAG_TOTAL_MAX_CHARS - rag_used_chars
                if len(txt) > remaining:
                    if remaining < 50:
                        break
                    txt = txt[:remaining] + ' â€¦'
                rag_snippets.append(f"- [ì¶œì²˜:{src}] {txt}")
                rag_used_chars += len(txt)
        rag_block = "\n".join(rag_snippets) if rag_snippets else "(ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ)"

        context = f"""
ë‹¹ì‹ ì€ ë§ˆì¸í¬ë˜í”„íŠ¸ ëª¨ë“œíŒ© ì „ë¬¸ê°€ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
í˜„ì¬ ëª¨ë“œíŒ©: {modpack_name} v{modpack_version}

ì•„ë˜ëŠ” ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ì¼ë¶€ì…ë‹ˆë‹¤(í•„ìš” ì‹œë§Œ ì°¸ê³ ):
{rag_block}

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ì œì‘ë²•, ì•„ì´í…œ ì •ë³´, ëª¨ë“œ ì„¤ëª… ë“±ì„ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

        # ì„ íƒëœ ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±
        if current_model == "gemini" and gemini_client:
            try:
                # ì›¹ê²€ìƒ‰ ë„êµ¬ ì„¤ì •
                config = None
                if GEMINI_WEBSEARCH_ENABLED:
                    grounding_tool = types.Tool(google_search=types.GoogleSearch())
                    config = types.GenerateContentConfig(tools=[grounding_tool])
                
                full_message = context + "\n\nì‚¬ìš©ì: " + message + "\n\nìµœì‹  ì •ë³´ê°€ í•„ìš”í•˜ë‹¤ë©´ ì›¹ ê²€ìƒ‰ì„ í™œìš©í•´ì„œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."
                
                # ì›¹ê²€ìƒ‰ ì§€ì› ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±
                with track_model_usage("gemini-2.5-pro-web"):
                    if config is not None:
                        response = gemini_client.models.generate_content(
                            model=GEMINI_MODEL,
                            contents=full_message,
                            config=config
                        )
                    else:
                        response = gemini_client.models.generate_content(
                            model=GEMINI_MODEL,
                            contents=full_message
                        )
                    ai_response = response.text
            except Exception as e:
                print(f"Gemini ì›¹ê²€ìƒ‰ ëª¨ë“œ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë“œë¡œ í´ë°±: {e}")
                # ì›¹ê²€ìƒ‰ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ëª¨ë“œë¡œ í´ë°±
                try:
                    full_message = context + "\n\nì‚¬ìš©ì: " + message + "\n\nAI:"
                    response = gemini_client.models.generate_content(
                        model=GEMINI_MODEL,
                        contents=full_message
                    )
                    ai_response = response.text
                except Exception as e2:
                    ai_response = f"Gemini API ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e2)}"

        elif current_model == "openai" and openai_client:
            try:
                # 2025ë…„ ìµœì‹  OpenAI API ë°©ì‹
                response = openai_client.chat.completions.create(
                    model=OPENAI_MODEL_PRIMARY,  # í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥
                    messages=[
                        {"role": "system", "content": context},
                        {"role": "user", "content": message}
                    ],
                    max_tokens=1000,
                    temperature=0.7
                )
                ai_response = response.choices[0].message.content
            except Exception as e:
                print(f"OpenAI GPT-4o-mini ì‹¤íŒ¨, GPT-3.5-turboë¡œ í´ë°±: {e}")
                # í´ë°± ì‹œë„
                try:
                    response = openai_client.chat.completions.create(
                        model=OPENAI_MODEL_FALLBACK,
                        messages=[
                            {"role": "system", "content": context},
                            {"role": "user", "content": message}
                        ],
                        max_tokens=1000,
                        temperature=0.7
                    )
                    ai_response = response.choices[0].message.content
                except Exception as e2:
                    ai_response = "OpenAI API ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. í• ë‹¹ëŸ‰ì´ë‚˜ API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

        elif current_model == "claude" and claude_client:
            try:
                response = claude_client.messages.create(
                    model=CLAUDE_MODEL,  # í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥
                    max_tokens=1000,
                    messages=[
                        {"role": "user", "content": context + "\n\n" + message}
                    ]
                )
                ai_response = response.content[0].text
            except Exception as e:
                if "credit" in str(e).lower() or "billing" in str(e).lower():
                    ai_response = "Claude APIëŠ” ìœ ë£Œ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. í¬ë ˆë”§ì„ ì¶©ì „í•´ì£¼ì„¸ìš”."
                else:
                    ai_response = "Claude API ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

        else:
            ai_response = "í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. Gemini API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."

        return jsonify({
            "success": True,
            "response": ai_response,
            "model": current_model,
            "timestamp": datetime.now().isoformat(),
            "rag": {
                "enabled": rag_enabled,
                "hits": rag_hits_count,
                "used": rag_hits_count > 0,
                "top_k": RAG_TOP_K,
                "snippet_max_chars": RAG_SNIPPET_MAX_CHARS,
                "total_max_chars": RAG_TOTAL_MAX_CHARS,
                "used_chars": rag_used_chars
            },
            "websearch_enabled": GEMINI_WEBSEARCH_ENABLED
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/models', methods=['GET'])
def get_models():
    models = []
    
    if gemini_client:
        models.append({
            "id": "gemini",
            "name": "Gemini 2.5 Pro (ì›¹ê²€ìƒ‰ ì§€ì›)",
            "provider": "Google",
            "available": True,
            "current": current_model == "gemini"
        })
    
    if openai_client:
        models.append({
            "id": "openai",
            "name": "GPT-4o Mini / GPT-3.5 Turbo",
            "provider": "OpenAI",
            "available": True,
            "current": current_model == "openai"
        })
    
    if claude_client:
        models.append({
            "id": "claude",
            "name": "Claude 3.5 Sonnet",
            "provider": "Anthropic",
            "available": True,
            "current": current_model == "claude"
        })
    
    return jsonify({"models": models})

# ---------------- RAG ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸ ----------------
@app.route('/rag/build', methods=['POST'])
def rag_build():
    """ê°„ë‹¨í•œ RAG ì¸ë±ìŠ¤ êµ¬ì¶• API
    - ì…ë ¥ í˜•ì‹ 1: {"docs": [{"text": "...", "source": "..."}, ...]}
    - ì…ë ¥ í˜•ì‹ 2: {"modpack_name": "...", "modpack_version": "...", "docs": [...]} (ë©”íƒ€ í¬í•¨)
    """
    try:
        data = request.get_json(force=True) or {}
        docs = data.get('docs', [])
        if not isinstance(docs, list) or not docs:
            return jsonify({"success": False, "error": "docs ë¦¬ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400
        # ìµœì†Œ í•„ë“œ ë³´ì •
        normalized = []
        for d in docs:
            if isinstance(d, dict) and d.get('text'):
                normalized.append({
                    'text': d.get('text', ''),
                    'source': d.get('source', 'manual')
                })
        if not normalized:
            return jsonify({"success": False, "error": "ìœ íš¨í•œ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤"}), 400
        ok = build_rag(normalized)
        return jsonify({"success": ok, "count": len(normalized)})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/rag/status', methods=['GET'])
def rag_status():
    return jsonify({
        "enabled": rag_enabled,
        "documents": len(rag_documents),
        "model": bool(rag_model)
    })

@app.route('/rag/save', methods=['POST'])
def rag_save():
    ok = rag_save_to_disk()
    return jsonify({"success": ok})

@app.route('/rag/load', methods=['POST'])
def rag_load():
    ok = rag_load_from_disk()
    return jsonify({"success": ok})

@app.route('/models/switch', methods=['POST'])
def switch_model():
    global current_model
    try:
        data = request.json
        model_id = data.get('model_id', 'gemini')

        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì¸ì§€ í™•ì¸
        available_models = []
        if gemini_client:
            available_models.append('gemini')
        if openai_client:
            available_models.append('openai')
        if claude_client:
            available_models.append('claude')

        if model_id in available_models:
            current_model = model_id
            return jsonify({
                "success": True,
                "message": f"ëª¨ë¸ì´ {model_id}ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤."
            })
        else:
            return jsonify({
                "success": False,
                "error": "ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ì´ê±°ë‚˜ API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            }), 400

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/modpack/switch', methods=['POST'])
def api_modpack_switch():
    """ê°„ì†Œí™”ëœ ëª¨ë“œíŒ© ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸.
    í˜„ì¬ëŠ” ì‹¤ì œ ë¶„ì„ ëŒ€ì‹  ì…ë ¥ê°’ì„ ê²€ì¦í•˜ê³  ê¸°ë³¸ ë©”íŠ¸ë¦­ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    modpack_switch.shê°€ ê¸°ëŒ€í•˜ëŠ” í•„ë“œë¥¼ í¬í•¨í•´ ì„±ê³µì ìœ¼ë¡œ ë™ì‘í•˜ë„ë¡ ë§ì¶¥ë‹ˆë‹¤.
    """
    try:
        data = request.get_json(force=True) or {}
        modpack_path = data.get('modpack_path', '')
        modpack_name = data.get('modpack_name', 'unknown')
        modpack_version = data.get('modpack_version', '1.0')

        # ê°„ë‹¨í•œ ìœ íš¨ì„± ê²€ì‚¬
        if not modpack_name:
            return jsonify({"success": False, "error": "modpack_name is required"}), 400

        # ê°„ë‹¨ ìŠ¤ìº” + RAG ìë™ êµ¬ì¶•
        stats = {}
        built = False
        if modpack_path and os.path.isdir(modpack_path):
            scan = scan_modpack(modpack_path)
            docs = scan.get('docs', [])
            stats = scan.get('stats', {})
            if docs:
                built = build_rag(docs)

        # ë°˜í™˜ í¬ë§·ì€ ìŠ¤í¬ë¦½íŠ¸ê°€ íŒŒì‹±í•˜ëŠ” í‚¤ì™€ ì¼ì¹˜í•´ì•¼ í•¨
        result = {
            "success": True,
            "modpack": {
                "name": modpack_name,
                "version": modpack_version,
                "path": modpack_path,
            },
            "mods_count": stats.get('mods', 0),
            "recipes_count": stats.get('recipes', 0),
            "items_count": stats.get('kubejs', 0),
            "rag_built": built,
            "language_mappings_added": 0,
            "timestamp": datetime.now().isoformat()
        }
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/recipe/<item_name>', methods=['GET'])
def get_recipe(item_name):
    try:
        # í˜„ì¬ í™œì„± ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ ë ˆì‹œí”¼ ê²€ìƒ‰
        if current_model == "gemini" and gemini_client:
            try:
                # ì›¹ê²€ìƒ‰ ë„êµ¬ ì„¤ì •ìœ¼ë¡œ ìµœì‹  ë ˆì‹œí”¼ ì •ë³´ ê²€ìƒ‰
                grounding_tool = types.Tool(google_search=types.GoogleSearch())
                config = types.GenerateContentConfig(tools=[grounding_tool])
                
                query = f"ë§ˆì¸í¬ë˜í”„íŠ¸ì—ì„œ {item_name}ì˜ ì œì‘ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”. ì¬ë£Œì™€ ì œì‘ ë°©ë²•ì„ í¬í•¨í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”. ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•´ì„œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."
                
                response = gemini_client.models.generate_content(
                    model=GEMINI_MODEL,
                    contents=query,
                    config=config
                )
                recipe_text = response.text
            except Exception as e:
                print(f"Gemini ì›¹ê²€ìƒ‰ ë ˆì‹œí”¼ ê²€ìƒ‰ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë“œë¡œ í´ë°±: {e}")
                # í´ë°±: ê²€ìƒ‰ ì—†ì´ ë ˆì‹œí”¼ ìƒì„±
                try:
                    query = f"ë§ˆì¸í¬ë˜í”„íŠ¸ì—ì„œ {item_name}ì˜ ì œì‘ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”. ì¬ë£Œì™€ ì œì‘ ë°©ë²•ì„ í¬í•¨í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."
                    response = gemini_client.models.generate_content(
                        model=GEMINI_MODEL,
                        contents=query
                    )
                    recipe_text = response.text
                except:
                    recipe_text = f"{item_name}ì˜ ì œì‘ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²Œì„ ë‚´ ì œì‘ë²• ì±…ì„ í™•ì¸í•´ë³´ì„¸ìš”."
        
        elif current_model == "openai" and openai_client:
            try:
                query = f"ë§ˆì¸í¬ë˜í”„íŠ¸ì—ì„œ {item_name}ì˜ ì œì‘ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”. ì¬ë£Œì™€ ì œì‘ ë°©ë²•ì„ í¬í•¨í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."
                response = openai_client.chat.completions.create(
                    model=OPENAI_MODEL_PRIMARY,
                    messages=[{"role": "user", "content": query}],
                    max_tokens=500,
                    temperature=0.7
                )
                recipe_text = response.choices[0].message.content
            except:
                recipe_text = f"{item_name}ì˜ ì œì‘ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²Œì„ ë‚´ ì œì‘ë²• ì±…ì„ í™•ì¸í•´ë³´ì„¸ìš”."
        
        elif current_model == "claude" and claude_client:
            try:
                query = f"ë§ˆì¸í¬ë˜í”„íŠ¸ì—ì„œ {item_name}ì˜ ì œì‘ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”. ì¬ë£Œì™€ ì œì‘ ë°©ë²•ì„ í¬í•¨í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."
                response = claude_client.messages.create(
                    model=CLAUDE_MODEL,
                    max_tokens=500,
                    messages=[{"role": "user", "content": query}]
                )
                recipe_text = response.content[0].text
            except:
                recipe_text = f"{item_name}ì˜ ì œì‘ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²Œì„ ë‚´ ì œì‘ë²• ì±…ì„ í™•ì¸í•´ë³´ì„¸ìš”."
        else:
            recipe_text = f"{item_name}ì˜ ì œì‘ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²Œì„ ë‚´ ì œì‘ë²• ì±…ì„ í™•ì¸í•´ë³´ì„¸ìš”."

        # 3x3 ë ˆì‹œí”¼ êµ¬ì¡°(ìˆìœ¼ë©´ AI ì‘ë‹µ íŒŒì‹±, ê¸°ë³¸ì€ í…ìŠ¤íŠ¸ë§Œ)
        recipe_info = {
            "item": item_name,
            "recipe": recipe_text,
            "grid": [[None, None, None], [None, None, None], [None, None, None]],
            "materials": [],
            "crafting_type": "crafting_table"
        }

        return jsonify({
            "success": True,
            "recipe": recipe_info
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

if __name__ == '__main__':
    print("ğŸš€ ë§ˆì¸í¬ë˜í”„íŠ¸ AI ë°±ì—”ë“œ ì‹œì‘ ì¤‘...")
    print(f"ğŸ“Š í˜„ì¬ í™œì„± ëª¨ë¸: {current_model if current_model else 'ì—†ìŒ'}")
    print(f"ğŸ”‘ Google API (Gemini): {'âœ…' if gemini_client else 'âŒ'}")
    print(f"ğŸ”‘ OpenAI API: {'âœ…' if openai_client else 'âŒ'}")  
    print(f"ğŸ”‘ Anthropic API (Claude): {'âœ…' if claude_client else 'âŒ'}")
    
    if current_model:
        print(f"ğŸ¯ ì£¼ ì‚¬ìš© ëª¨ë¸: {current_model}")
        if current_model == "gemini":
            print("ğŸŒ Gemini ì›¹ê²€ìƒ‰ ê¸°ëŠ¥ í™œì„±í™”ë¨")
    else:
        print("âš ï¸ ê²½ê³ : ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
        print("ğŸ’¡ ìµœì†Œí•œ Google API í‚¤(Gemini)ë¥¼ ì„¤ì •í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
    
    print("=" * 60)
    init_rag()
    app.run(host='0.0.0.0', port=5000, debug=False)